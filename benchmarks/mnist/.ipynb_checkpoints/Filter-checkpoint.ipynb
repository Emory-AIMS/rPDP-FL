{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a90d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from fedrpdp.datasets.fed_mnist import (\n",
    "    BaselineModel,\n",
    "    BaselineLoss,\n",
    "    metric\n",
    ")\n",
    "\n",
    "from fedrpdp.utils.rpdp_utils import (\n",
    "    get_sample_rate_curve,\n",
    "    MultiLevels, \n",
    "    MixGauss, \n",
    "    Pareto,\n",
    ")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "lr = 0.5\n",
    "\n",
    "project_abspath = os.path.dirname(os.getcwd())\n",
    "DATA_ROOT = '/data/privacyGroup/liujunxu/datasets/mnist'\n",
    "\n",
    "train_data = MNIST(DATA_ROOT, train=True, download=False, transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "test_data = MNIST(DATA_ROOT, train=False, download=False, transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=len(train_data), # use all data points\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=len(test_data),\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model_init = BaselineModel().to(device)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "noise_multiplier = 5.0\n",
    "max_grad_norm = 5.0\n",
    "max_epochs = 100\n",
    "delta = 1e-5\n",
    "\n",
    "total_points = len(train_data)\n",
    "num_level1 = int(total_points * 0.7)\n",
    "num_level2 = int(total_points * 0.2)\n",
    "num_level3 = total_points - num_level1 - num_level2\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, metric, running_norms=None):\n",
    "    model.train()\n",
    "    data, target = next(iter(train_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "\n",
    "    # compute train acc\n",
    "    correct = metric(target.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "    train_acc = correct / len(target)\n",
    "    \n",
    "    # compute train loss\n",
    "    loss = criterion(output, target)\n",
    "    train_loss = loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    if running_norms is not None:\n",
    "        gradient_norms = optimizer.step(running_norms)\n",
    "        gradient_norms_sq = gradient_norms * gradient_norms\n",
    "        return train_loss, train_acc, gradient_norms_sq\n",
    "    \n",
    "    else:\n",
    "        optimizer.step()\n",
    "        return train_loss, train_acc\n",
    "    \n",
    "\n",
    "def test(model, device, test_loader, criterion, metric):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, target = next(iter(test_loader))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss = criterion(output, target).item()\n",
    "        \n",
    "        correct = metric(target.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "        test_acc = 1. * correct / len(target)\n",
    "        print(correct, len(target))\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2530d",
   "metadata": {},
   "source": [
    "# GD with RDP Filter (NeurIPS'21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354a922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdp import PrivacyEngine\n",
    "from fedrpdp.accountants.utils import get_noise_multiplier\n",
    "\n",
    "def generate_rdp_orders():\n",
    "    dense = 1.07\n",
    "    alpha_list = [int(dense ** i + 1) for i in range(int(math.floor(math.log(1000, dense))) + 1)]\n",
    "    alpha_list = np.unique(alpha_list)\n",
    "    return alpha_list\n",
    "\n",
    "norm_sq_budgets = [100] * num_level1 + [500] * num_level2 + [2500] * num_level3\n",
    "\n",
    "_model = copy.deepcopy(model_init)\n",
    "_train_loader = copy.deepcopy(train_loader)\n",
    "optimizer = optim.SGD(_model.parameters(), lr=lr, momentum=0)\n",
    "criterion = BaselineLoss()\n",
    "privacy_engine = PrivacyEngine(\n",
    "    module=_model,\n",
    "    batch_size=total_points,\n",
    "    sample_size=total_points,\n",
    "    alphas=generate_rdp_orders(),\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    norm_sq_budget=norm_sq_budgets,\n",
    "    should_clip=True,\n",
    ")\n",
    "privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685b58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# privacy_engine.steps = int(privacy_engine.norm_sq_budget[0]/max_grad_norm**2) + 1\n",
    "# epsilon1 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[0], delta)[0]\n",
    "# privacy_engine.steps = int(privacy_engine.norm_sq_budget[42000]/max_grad_norm**2) + 1\n",
    "# epsilon2 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[42000], delta)[0]\n",
    "# privacy_engine.steps = int(privacy_engine.norm_sq_budget[54000]/max_grad_norm**2) + 1\n",
    "# epsilon3 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[54000], delta)[0]\n",
    "# print(\n",
    "#     f\"δ: {delta} ε1 = {epsilon1:.2f} ε2 = {epsilon2:.2f} ε3 = {epsilon3:.2f}.\"\n",
    "# )\n",
    "# privacy_engine.steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db575a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.97957 27.384346 24.19378\n",
      "Epoch: 1: seconds = 10.402732849121094\n",
      "Train Loss: 2.3069 \t Acc: 0.1049 | δ: 1e-05 ε1 = 0.9797 ε2 = 0.9797 ε3 = 0.9797.\n",
      "1355 10000\n",
      "Test  Loss: 2.2901 \t Acc: 0.1355\n",
      "\n",
      "38.89315 48.83638 42.095863\n",
      "Epoch: 2: seconds = 8.521914958953857\n",
      "Train Loss: 2.2901 \t Acc: 0.1347 | δ: 1e-05 ε1 = 0.9797 ε2 = 1.3972 ε3 = 1.3972.\n",
      "1731 10000\n",
      "Test  Loss: 2.2783 \t Acc: 0.1731\n",
      "\n",
      "58.586983 72.31065 64.689644\n",
      "Epoch: 3: seconds = 8.4428129196167\n",
      "Train Loss: 2.2789 \t Acc: 0.1735 | δ: 1e-05 ε1 = 0.9797 ε2 = 1.7224 ε3 = 1.7224.\n",
      "1831 10000\n",
      "Test  Loss: 2.2733 \t Acc: 0.1831\n",
      "\n",
      "69.961494 91.73306 78.84592\n",
      "Epoch: 4: seconds = 8.376971244812012\n",
      "Train Loss: 2.2733 \t Acc: 0.1834 | δ: 1e-05 ε1 = 0.9797 ε2 = 1.9994 ε3 = 1.9994.\n",
      "1165 10000\n",
      "Test  Loss: 2.2722 \t Acc: 0.1165\n",
      "\n",
      "99.789734 120.50515 104.62121\n",
      "Epoch: 5: seconds = 8.345195055007935\n",
      "Train Loss: 2.2733 \t Acc: 0.1151 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 2.2466.\n",
      "1069 10000\n",
      "Test  Loss: 2.2550 \t Acc: 0.1069\n",
      "\n",
      "100.0 140.40471 119.36687\n",
      "Epoch: 6: seconds = 7.045099496841431\n",
      "Train Loss: 2.2548 \t Acc: 0.1085 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 2.4713.\n",
      "1028 10000\n",
      "Test  Loss: 2.2184 \t Acc: 0.1028\n",
      "\n",
      "100.0 164.58223 154.96411\n",
      "Epoch: 7: seconds = 6.954667806625366\n",
      "Train Loss: 2.2191 \t Acc: 0.1045 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 2.6792.\n",
      "1028 10000\n",
      "Test  Loss: 2.2184 \t Acc: 0.1028\n",
      "\n",
      "100.0 211.54068 207.95964\n",
      "Epoch: 8: seconds = 7.051207542419434\n",
      "Train Loss: 2.2199 \t Acc: 0.1044 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 2.8791.\n",
      "3715 10000\n",
      "Test  Loss: 2.1237 \t Acc: 0.3715\n",
      "\n",
      "100.0 243.24104 252.57925\n",
      "Epoch: 9: seconds = 7.090307235717773\n",
      "Train Loss: 2.1266 \t Acc: 0.3725 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.0591.\n",
      "3763 10000\n",
      "Test  Loss: 2.0659 \t Acc: 0.3763\n",
      "\n",
      "100.0 276.60986 301.37732\n",
      "Epoch: 10: seconds = 7.0752081871032715\n",
      "Train Loss: 2.0691 \t Acc: 0.3743 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.2391.\n",
      "4087 10000\n",
      "Test  Loss: 2.0074 \t Acc: 0.4087\n",
      "\n",
      "100.0 311.0699 356.61353\n",
      "Epoch: 11: seconds = 7.259027004241943\n",
      "Train Loss: 2.0113 \t Acc: 0.4031 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.4047.\n",
      "4969 10000\n",
      "Test  Loss: 1.9368 \t Acc: 0.4969\n",
      "\n",
      "100.0 351.0216 419.71353\n",
      "Epoch: 12: seconds = 7.129869699478149\n",
      "Train Loss: 1.9416 \t Acc: 0.4861 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.5647.\n",
      "5085 10000\n",
      "Test  Loss: 1.8532 \t Acc: 0.5085\n",
      "\n",
      "100.0 392.99982 506.71478\n",
      "Epoch: 13: seconds = 7.070099353790283\n",
      "Train Loss: 1.8595 \t Acc: 0.4982 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.7247.\n",
      "5151 10000\n",
      "Test  Loss: 1.7608 \t Acc: 0.5151\n",
      "\n",
      "100.0 454.85056 606.7148\n",
      "Epoch: 14: seconds = 6.976139068603516\n",
      "Train Loss: 1.7684 \t Acc: 0.5035 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 3.8788.\n",
      "4525 10000\n",
      "Test  Loss: 1.6996 \t Acc: 0.4525\n",
      "\n",
      "100.0 493.11963 706.7148\n",
      "Epoch: 15: seconds = 7.22999382019043\n",
      "Train Loss: 1.7101 \t Acc: 0.4476 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.0188.\n",
      "5720 10000\n",
      "Test  Loss: 1.6268 \t Acc: 0.5720\n",
      "\n",
      "100.0 500.0 806.7148\n",
      "Epoch: 16: seconds = 7.181206941604614\n",
      "Train Loss: 1.6377 \t Acc: 0.5604 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.1588.\n",
      "5194 10000\n",
      "Test  Loss: 1.5429 \t Acc: 0.5194\n",
      "\n",
      "100.0 500.0 906.7148\n",
      "Epoch: 17: seconds = 7.054748773574829\n",
      "Train Loss: 1.5565 \t Acc: 0.5108 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.2988.\n",
      "6379 10000\n",
      "Test  Loss: 1.4597 \t Acc: 0.6379\n",
      "\n",
      "100.0 500.0 1006.7148\n",
      "Epoch: 18: seconds = 7.069782018661499\n",
      "Train Loss: 1.4740 \t Acc: 0.6290 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.4388.\n",
      "6523 10000\n",
      "Test  Loss: 1.4094 \t Acc: 0.6523\n",
      "\n",
      "100.0 500.0 1106.7147\n",
      "Epoch: 19: seconds = 7.0908050537109375\n",
      "Train Loss: 1.4250 \t Acc: 0.6441 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.5788.\n",
      "6646 10000\n",
      "Test  Loss: 1.3600 \t Acc: 0.6646\n",
      "\n",
      "100.0 500.0 1206.7147\n",
      "Epoch: 20: seconds = 7.100772142410278\n",
      "Train Loss: 1.3767 \t Acc: 0.6586 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.7026.\n",
      "6752 10000\n",
      "Test  Loss: 1.3135 \t Acc: 0.6752\n",
      "\n",
      "100.0 500.0 1306.7147\n",
      "Epoch: 21: seconds = 7.0802693367004395\n",
      "Train Loss: 1.3311 \t Acc: 0.6687 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.8226.\n",
      "6871 10000\n",
      "Test  Loss: 1.2678 \t Acc: 0.6871\n",
      "\n",
      "100.0 500.0 1406.7147\n",
      "Epoch: 22: seconds = 7.061172962188721\n",
      "Train Loss: 1.2864 \t Acc: 0.6806 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 4.9426.\n",
      "7003 10000\n",
      "Test  Loss: 1.2239 \t Acc: 0.7003\n",
      "\n",
      "100.0 500.0 1506.7147\n",
      "Epoch: 23: seconds = 7.173391819000244\n",
      "Train Loss: 1.2432 \t Acc: 0.6919 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.0626.\n",
      "7108 10000\n",
      "Test  Loss: 1.1818 \t Acc: 0.7108\n",
      "\n",
      "100.0 500.0 1606.7147\n",
      "Epoch: 24: seconds = 7.182314395904541\n",
      "Train Loss: 1.2019 \t Acc: 0.7028 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.1826.\n",
      "7228 10000\n",
      "Test  Loss: 1.1417 \t Acc: 0.7228\n",
      "\n",
      "100.0 500.0 1706.7147\n",
      "Epoch: 25: seconds = 7.075707674026489\n",
      "Train Loss: 1.1626 \t Acc: 0.7130 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7324 10000\n",
      "Test  Loss: 1.1031 \t Acc: 0.7324\n",
      "\n",
      "100.0 500.0 1806.7147\n",
      "Epoch: 26: seconds = 6.9811906814575195\n",
      "Train Loss: 1.1247 \t Acc: 0.7227 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7421 10000\n",
      "Test  Loss: 1.0660 \t Acc: 0.7421\n",
      "\n",
      "100.0 500.0 1906.7147\n",
      "Epoch: 27: seconds = 7.203734636306763\n",
      "Train Loss: 1.0883 \t Acc: 0.7315 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7462 10000\n",
      "Test  Loss: 1.0326 \t Acc: 0.7462\n",
      "\n",
      "100.0 500.0 2006.7147\n",
      "Epoch: 28: seconds = 7.194459438323975\n",
      "Train Loss: 1.0553 \t Acc: 0.7375 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7572 10000\n",
      "Test  Loss: 0.9981 \t Acc: 0.7572\n",
      "\n",
      "100.0 500.0 2106.7146\n",
      "Epoch: 29: seconds = 7.073865175247192\n",
      "Train Loss: 1.0215 \t Acc: 0.7485 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7610 10000\n",
      "Test  Loss: 0.9677 \t Acc: 0.7610\n",
      "\n",
      "100.0 500.0 2206.7146\n",
      "Epoch: 30: seconds = 7.049397230148315\n",
      "Train Loss: 0.9916 \t Acc: 0.7529 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7682 10000\n",
      "Test  Loss: 0.9366 \t Acc: 0.7682\n",
      "\n",
      "100.0 500.0 2306.7146\n",
      "Epoch: 31: seconds = 6.978795051574707\n",
      "Train Loss: 0.9611 \t Acc: 0.7607 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7709 10000\n",
      "Test  Loss: 0.9099 \t Acc: 0.7709\n",
      "\n",
      "100.0 500.0 2406.7146\n",
      "Epoch: 32: seconds = 7.260239124298096\n",
      "Train Loss: 0.9347 \t Acc: 0.7655 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7789 10000\n",
      "Test  Loss: 0.8814 \t Acc: 0.7789\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 33: seconds = 7.070948839187622\n",
      "Train Loss: 0.9068 \t Acc: 0.7733 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7790 10000\n",
      "Test  Loss: 0.8585 \t Acc: 0.7790\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 34: seconds = 7.075311660766602\n",
      "Train Loss: 0.8841 \t Acc: 0.7741 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7631 10000\n",
      "Test  Loss: 0.8565 \t Acc: 0.7631\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 35: seconds = 7.06132435798645\n",
      "Train Loss: 0.8822 \t Acc: 0.7559 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "7079 10000\n",
      "Test  Loss: 0.9178 \t Acc: 0.7079\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 36: seconds = 7.265412092208862\n",
      "Train Loss: 0.9436 \t Acc: 0.6968 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6750 10000\n",
      "Test  Loss: 0.9666 \t Acc: 0.6750\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 37: seconds = 7.077563524246216\n",
      "Train Loss: 0.9926 \t Acc: 0.6620 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6539 10000\n",
      "Test  Loss: 0.9949 \t Acc: 0.6539\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 38: seconds = 6.9544501304626465\n",
      "Train Loss: 1.0220 \t Acc: 0.6423 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6418 10000\n",
      "Test  Loss: 1.0192 \t Acc: 0.6418\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 39: seconds = 7.073349714279175\n",
      "Train Loss: 1.0469 \t Acc: 0.6279 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6324 10000\n",
      "Test  Loss: 1.0392 \t Acc: 0.6324\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 40: seconds = 7.068135738372803\n",
      "Train Loss: 1.0675 \t Acc: 0.6164 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6196 10000\n",
      "Test  Loss: 1.0603 \t Acc: 0.6196\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 41: seconds = 7.21051287651062\n",
      "Train Loss: 1.0891 \t Acc: 0.6033 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6109 10000\n",
      "Test  Loss: 1.0822 \t Acc: 0.6109\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 42: seconds = 7.137083530426025\n",
      "Train Loss: 1.1115 \t Acc: 0.5926 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "6018 10000\n",
      "Test  Loss: 1.1013 \t Acc: 0.6018\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 43: seconds = 6.968884468078613\n",
      "Train Loss: 1.1311 \t Acc: 0.5834 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5905 10000\n",
      "Test  Loss: 1.1246 \t Acc: 0.5905\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 44: seconds = 7.063520908355713\n",
      "Train Loss: 1.1551 \t Acc: 0.5727 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5824 10000\n",
      "Test  Loss: 1.1406 \t Acc: 0.5824\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 45: seconds = 7.075235843658447\n",
      "Train Loss: 1.1715 \t Acc: 0.5652 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5758 10000\n",
      "Test  Loss: 1.1525 \t Acc: 0.5758\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 46: seconds = 7.118883848190308\n",
      "Train Loss: 1.1835 \t Acc: 0.5601 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5666 10000\n",
      "Test  Loss: 1.1677 \t Acc: 0.5666\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 47: seconds = 7.119960784912109\n",
      "Train Loss: 1.1987 \t Acc: 0.5534 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5585 10000\n",
      "Test  Loss: 1.1862 \t Acc: 0.5585\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 48: seconds = 7.2267491817474365\n",
      "Train Loss: 1.2177 \t Acc: 0.5463 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5540 10000\n",
      "Test  Loss: 1.1974 \t Acc: 0.5540\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 49: seconds = 7.130969524383545\n",
      "Train Loss: 1.2291 \t Acc: 0.5416 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5502 10000\n",
      "Test  Loss: 1.2054 \t Acc: 0.5502\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 50: seconds = 6.945814609527588\n",
      "Train Loss: 1.2373 \t Acc: 0.5387 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5432 10000\n",
      "Test  Loss: 1.2211 \t Acc: 0.5432\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 51: seconds = 7.070398807525635\n",
      "Train Loss: 1.2531 \t Acc: 0.5334 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5377 10000\n",
      "Test  Loss: 1.2352 \t Acc: 0.5377\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 52: seconds = 7.083172082901001\n",
      "Train Loss: 1.2672 \t Acc: 0.5292 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5346 10000\n",
      "Test  Loss: 1.2420 \t Acc: 0.5346\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 53: seconds = 7.115029573440552\n",
      "Train Loss: 1.2742 \t Acc: 0.5269 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5332 10000\n",
      "Test  Loss: 1.2480 \t Acc: 0.5332\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 54: seconds = 7.18218994140625\n",
      "Train Loss: 1.2804 \t Acc: 0.5254 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5306 10000\n",
      "Test  Loss: 1.2569 \t Acc: 0.5306\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 55: seconds = 7.000195264816284\n",
      "Train Loss: 1.2897 \t Acc: 0.5232 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5292 10000\n",
      "Test  Loss: 1.2647 \t Acc: 0.5292\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 56: seconds = 7.092679977416992\n",
      "Train Loss: 1.2975 \t Acc: 0.5216 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5275 10000\n",
      "Test  Loss: 1.2714 \t Acc: 0.5275\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 57: seconds = 7.078241348266602\n",
      "Train Loss: 1.3043 \t Acc: 0.5206 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5264 10000\n",
      "Test  Loss: 1.2744 \t Acc: 0.5264\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 58: seconds = 7.060569763183594\n",
      "Train Loss: 1.3074 \t Acc: 0.5196 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5226 10000\n",
      "Test  Loss: 1.2859 \t Acc: 0.5226\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 59: seconds = 7.071709394454956\n",
      "Train Loss: 1.3191 \t Acc: 0.5164 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5209 10000\n",
      "Test  Loss: 1.2966 \t Acc: 0.5209\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 60: seconds = 7.170650959014893\n",
      "Train Loss: 1.3301 \t Acc: 0.5140 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5197 10000\n",
      "Test  Loss: 1.3050 \t Acc: 0.5197\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 61: seconds = 7.223081827163696\n",
      "Train Loss: 1.3387 \t Acc: 0.5125 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5172 10000\n",
      "Test  Loss: 1.3134 \t Acc: 0.5172\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 62: seconds = 6.9760637283325195\n",
      "Train Loss: 1.3471 \t Acc: 0.5101 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5137 10000\n",
      "Test  Loss: 1.3270 \t Acc: 0.5137\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 63: seconds = 7.1347126960754395\n",
      "Train Loss: 1.3609 \t Acc: 0.5068 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5127 10000\n",
      "Test  Loss: 1.3330 \t Acc: 0.5127\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 64: seconds = 7.094159841537476\n",
      "Train Loss: 1.3669 \t Acc: 0.5060 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5106 10000\n",
      "Test  Loss: 1.3405 \t Acc: 0.5106\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 65: seconds = 7.108508348464966\n",
      "Train Loss: 1.3745 \t Acc: 0.5043 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5085 10000\n",
      "Test  Loss: 1.3499 \t Acc: 0.5085\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 66: seconds = 7.144793272018433\n",
      "Train Loss: 1.3843 \t Acc: 0.5027 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5081 10000\n",
      "Test  Loss: 1.3547 \t Acc: 0.5081\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 67: seconds = 7.137984752655029\n",
      "Train Loss: 1.3892 \t Acc: 0.5021 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5067 10000\n",
      "Test  Loss: 1.3571 \t Acc: 0.5067\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 68: seconds = 7.084927558898926\n",
      "Train Loss: 1.3918 \t Acc: 0.5011 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5056 10000\n",
      "Test  Loss: 1.3637 \t Acc: 0.5056\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 69: seconds = 7.0962982177734375\n",
      "Train Loss: 1.3985 \t Acc: 0.5002 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5051 10000\n",
      "Test  Loss: 1.3667 \t Acc: 0.5051\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 70: seconds = 7.055815935134888\n",
      "Train Loss: 1.4014 \t Acc: 0.5002 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5040 10000\n",
      "Test  Loss: 1.3711 \t Acc: 0.5040\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 71: seconds = 7.197216033935547\n",
      "Train Loss: 1.4060 \t Acc: 0.4993 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5015 10000\n",
      "Test  Loss: 1.3850 \t Acc: 0.5015\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 72: seconds = 7.118348121643066\n",
      "Train Loss: 1.4199 \t Acc: 0.4975 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5011 10000\n",
      "Test  Loss: 1.3871 \t Acc: 0.5011\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 73: seconds = 7.0905163288116455\n",
      "Train Loss: 1.4221 \t Acc: 0.4972 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "5010 10000\n",
      "Test  Loss: 1.3867 \t Acc: 0.5010\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 74: seconds = 6.933272123336792\n",
      "Train Loss: 1.4215 \t Acc: 0.4971 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4996 10000\n",
      "Test  Loss: 1.3932 \t Acc: 0.4996\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 75: seconds = 7.223541736602783\n",
      "Train Loss: 1.4283 \t Acc: 0.4963 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4975 10000\n",
      "Test  Loss: 1.4028 \t Acc: 0.4975\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 76: seconds = 7.093763113021851\n",
      "Train Loss: 1.4380 \t Acc: 0.4944 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4973 10000\n",
      "Test  Loss: 1.4066 \t Acc: 0.4973\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 77: seconds = 7.037826061248779\n",
      "Train Loss: 1.4420 \t Acc: 0.4943 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4955 10000\n",
      "Test  Loss: 1.4160 \t Acc: 0.4955\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 78: seconds = 7.071707725524902\n",
      "Train Loss: 1.4515 \t Acc: 0.4924 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4950 10000\n",
      "Test  Loss: 1.4233 \t Acc: 0.4950\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 79: seconds = 6.975373983383179\n",
      "Train Loss: 1.4589 \t Acc: 0.4913 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4945 10000\n",
      "Test  Loss: 1.4292 \t Acc: 0.4945\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 80: seconds = 7.19886326789856\n",
      "Train Loss: 1.4649 \t Acc: 0.4907 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4939 10000\n",
      "Test  Loss: 1.4294 \t Acc: 0.4939\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 81: seconds = 7.1143434047698975\n",
      "Train Loss: 1.4653 \t Acc: 0.4907 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4940 10000\n",
      "Test  Loss: 1.4347 \t Acc: 0.4940\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 82: seconds = 7.124945163726807\n",
      "Train Loss: 1.4707 \t Acc: 0.4899 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4918 10000\n",
      "Test  Loss: 1.4457 \t Acc: 0.4918\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 83: seconds = 7.114345550537109\n",
      "Train Loss: 1.4821 \t Acc: 0.4888 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4903 10000\n",
      "Test  Loss: 1.4562 \t Acc: 0.4903\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 84: seconds = 7.096340656280518\n",
      "Train Loss: 1.4925 \t Acc: 0.4878 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4888 10000\n",
      "Test  Loss: 1.4648 \t Acc: 0.4888\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 85: seconds = 7.131037712097168\n",
      "Train Loss: 1.5012 \t Acc: 0.4870 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4876 10000\n",
      "Test  Loss: 1.4689 \t Acc: 0.4876\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 86: seconds = 7.02811074256897\n",
      "Train Loss: 1.5058 \t Acc: 0.4862 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4875 10000\n",
      "Test  Loss: 1.4732 \t Acc: 0.4875\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 87: seconds = 7.054710865020752\n",
      "Train Loss: 1.5103 \t Acc: 0.4861 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4872 10000\n",
      "Test  Loss: 1.4743 \t Acc: 0.4872\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 88: seconds = 7.04767632484436\n",
      "Train Loss: 1.5113 \t Acc: 0.4855 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4873 10000\n",
      "Test  Loss: 1.4763 \t Acc: 0.4873\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 89: seconds = 7.036116123199463\n",
      "Train Loss: 1.5131 \t Acc: 0.4852 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4863 10000\n",
      "Test  Loss: 1.4783 \t Acc: 0.4863\n",
      "\n",
      "100.0 500.0 2500.0\n",
      "Epoch: 90: seconds = 7.098005294799805\n",
      "Train Loss: 1.5147 \t Acc: 0.4843 | δ: 1e-05 ε1 = 0.9797 ε2 = 2.2466 ε3 = 5.3026.\n",
      "4865 10000\n",
      "Test  Loss: 1.4834 \t Acc: 0.4865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "running_grad_sq_norms = [ torch.Tensor([0] * total_points).to(device) ]\n",
    "results_all_reps = [\n",
    "    {\n",
    "        \"test_loss\": 0, \n",
    "        \"test_acc\": 0, \n",
    "        \"seconds\": 0, \n",
    "        \"num_active_points\": total_points,\n",
    "        \"norm_sq_budgets\": set(norm_sq_budgets), \n",
    "        \"e\": json.dumps({0: 0, num_level1:0, num_level1+num_level2:0}), \n",
    "        \"d\": delta, \n",
    "        \"nm\": round(noise_multiplier, 2), \n",
    "        \"norm\": max_grad_norm\n",
    "    }\n",
    "]\n",
    "\n",
    "for epoch in range(1, max_epochs + 51):\n",
    "    # compute activate points\n",
    "    temp = running_grad_sq_norms[-1].cpu().numpy()\n",
    "    num_active_points = np.sum(np.round(temp, 4) < np.array(norm_sq_budgets))\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, grad_sq_norms = train(_model, device, _train_loader, optimizer, criterion, metric, running_grad_sq_norms[-1])\n",
    "#     train_loss, train_acc = train(_model, device, _train_loader, optimizer, criterion, metric)\n",
    "\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "    running_grad_sq_norms.append(running_grad_sq_norms[-1] + grad_sq_norms)\n",
    "    \n",
    "    epsilon1 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[0], delta)[0]\n",
    "    epsilon2 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1], delta)[0]\n",
    "    epsilon3 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1 + num_level2], delta)[0]\n",
    "    \n",
    "    temp = running_grad_sq_norms[-1].cpu().numpy()\n",
    "    print(temp[0], temp[num_level1], temp[num_level1+num_level2])\n",
    "    \n",
    "    print(f\"Epoch: {epoch}: seconds = {seconds}\")\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.4f} \\t Acc: {train_acc:.4f} \"\n",
    "        f\"| δ: {delta} ε1 = {epsilon1:.4f} ε2 = {epsilon2:.4f} ε3 = {epsilon3:.4f}.\"\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = test(_model, device, test_loader, criterion, metric)\n",
    "    print(\n",
    "        f\"Test  Loss: {test_loss:.4f} \\t Acc: {test_acc:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    results_all_reps.append(\n",
    "        {\n",
    "            \"test_loss\": round(test_loss,4), \n",
    "            \"test_acc\": round(test_acc,4), \n",
    "            \"seconds\": round(seconds,4), \n",
    "            \"num_active_points\": num_active_points.item(),\n",
    "            \"norm_sq_budgets\": set(running_grad_sq_norms[-1].cpu().numpy()),\n",
    "            \"e\": json.dumps({0:epsilon1, num_level1:epsilon2, num_level1+num_level2:epsilon3}), \n",
    "            \"d\": delta, \n",
    "            \"nm\": round(noise_multiplier,2), \n",
    "            \"norm\": max_grad_norm\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results = pd.DataFrame.from_dict(results_all_reps)\n",
    "    results.to_csv(\"results_filter.csv\", index=False)\n",
    "    \n",
    "    if num_active_points < 10:\n",
    "        break\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a7d41",
   "metadata": {},
   "source": [
    "Q: running_grad_sq_norm 与 epsilon 不匹配：epsilon 需在 running_grad_sq_norm 增长过程中，同步达到给定的 epsilon budget？\n",
    "A: 首先看 `get_epsilon()` 的代码:\n",
    "``` Python\n",
    "rdp = self.get_renyi_divergence() * min(self.steps, norm_sq_budget/self.max_grad_norm**2)\n",
    "return tf_privacy.get_privacy_spent(self.alphas, rdp, target_delta)\n",
    "```\n",
    "可见，当 self.steps > norm_sq_budget/max_grad_norm^2 时，rdp不会再变化（导致计算的epsilon不再变化），但 running_grad_sq_norm 还在增加。\n",
    "\n",
    "另外：\n",
    "1. 若 nm 确定了，则 self.get_renyi_divergence() 便确定了；而 nm 的大小是根据 MAX_EPSILON 与 MAX_EPOCHS 得到的（即条件是当达到MAX_EPOCHS时，达到 MAX_EPSILON；\n",
    "2. 若 actual steps 与 norm_sq_budget/max_grad_norm^2 差距特别大，说明选择的 max_grad_norm 太大，需适当调小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5622be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedrpdp.accountants.utils import get_noise_multiplier\n",
    "from fedrpdp import PrivacyEngine\n",
    "\n",
    "curve_fn = get_sample_rate_curve(\n",
    "    target_delta = delta,\n",
    "    noise_multiplier = noise_multiplier,\n",
    "    num_updates = max_epochs,\n",
    "    num_rounds = None,\n",
    "    client_rate = None\n",
    ")\n",
    "epsilon_budgets = [epsilon1] * num_level1 + [epsilon2] * num_level2 + [epsilon3] * num_level3\n",
    "\n",
    "_model = copy.deepcopy(model_init)\n",
    "_train_loader = copy.deepcopy(train_loader)\n",
    "optimizer = optim.SGD(_model.parameters(), lr=lr, momentum=0)\n",
    "criterion = BaselineLoss()\n",
    "\n",
    "privacy_engine = PrivacyEngine(accountant=\"pers_rdp\", noise_multiplier=noise_multiplier)\n",
    "privacy_engine.sample_rate_fn = curve_fn\n",
    "per_sample_rate = [float(privacy_engine.sample_rate_fn(x)) for x in epsilon_budgets]\n",
    "print(round(min(epsilon_budgets),4), round(min(per_sample_rate),4))\n",
    "print(round(max(epsilon_budgets),4), round(max(per_sample_rate),4))\n",
    "if max(per_sample_rate) == 0.0:\n",
    "    raise ValueError(\"Hyper parameter errors! The maximum value of per_sample_rates is zero!\")\n",
    "privacy_engine.sample_rate = per_sample_rate # TODO: make it as an internal func of PrivacyEngine\n",
    "print(set(privacy_engine.sample_rate))\n",
    "\n",
    "_model, optimizer, _train_loader = privacy_engine.make_private_with_personalization(\n",
    "    module=_model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=_train_loader,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm\n",
    ")\n",
    "results_all_reps = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = train(_model, device, _train_loader, optimizer, criterion, metric)\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "    \n",
    "    test_loss, test_acc = test(_model, device, test_loader, criterion, metric)\n",
    "    \n",
    "    epsilon_1 = privacy_engine.get_epsilon(0, delta)\n",
    "    epsilon_2 = privacy_engine.get_epsilon(num_level1, delta)\n",
    "    epsilon_3 = privacy_engine.get_epsilon(num_level1+num_level2, delta)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.6f} \\t Acc: {100*train_acc:.2f}% \"\n",
    "        f\"| δ: {delta} \"\n",
    "        f\"ε1 = {epsilon_1:.4f}, \"\n",
    "        f\"ε2 = {epsilon_2:.4f}, \"\n",
    "        f\"ε3 = {epsilon_3:.4f}, \"\n",
    "    )\n",
    "        \n",
    "    print(\"Test  Loss: {:.4f} \\t Acc: {:.2f}%\\n\".format(test_loss, 100*test_acc))\n",
    "    results_all_reps.append(\n",
    "        {\n",
    "            \"test_loss\": round(test_loss,4), \"test_acc\": round(test_acc,4), \n",
    "             \"seconds\": round(seconds,4),\n",
    "             \"e\": set(epsilon_budgets), \"d\": delta, \"nm\": round(noise_multiplier,2), \"norm\": max_grad_norm\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    results = pd.DataFrame.from_dict(results_all_reps)\n",
    "    results.to_csv(\"results_ours.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
