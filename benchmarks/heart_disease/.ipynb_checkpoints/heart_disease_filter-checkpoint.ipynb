{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca20f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "from fedrpdp.datasets.fed_heart_disease import (\n",
    "    BaselineModel,\n",
    "    BaselineLoss,\n",
    "    FedHeartDisease,\n",
    "    metric,\n",
    ")\n",
    "\n",
    "from fedrpdp.utils.rpdp_utils import (\n",
    "    get_sample_rate_curve,\n",
    "    MultiLevels, \n",
    "    MixGauss, \n",
    "    Pareto,\n",
    ")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "lr = 0.1\n",
    "\n",
    "train_data = FedHeartDisease(train=True, pooled=True)\n",
    "test_data = FedHeartDisease(train=False, pooled=True)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=len(train_data),\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=len(test_data),\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model_init = BaselineModel().to(device)\n",
    "torch.manual_seed(42) \n",
    "\n",
    "noise_multiplier = 10.0\n",
    "max_grad_norm = 1.0\n",
    "max_epochs = 100\n",
    "delta = 1e-3\n",
    "\n",
    "total_points = len(train_data)\n",
    "num_level1 = int(total_points * 0.7)\n",
    "num_level2 = int(total_points * 0.2)\n",
    "num_level3 = total_points - num_level1 - num_level2\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, metric, running_norms=None):\n",
    "    model.train()\n",
    "    data, target = next(iter(train_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "\n",
    "    # compute train acc\n",
    "    correct = metric(target.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "    train_acc = correct / len(target)\n",
    "    \n",
    "    # compute train loss\n",
    "    loss = criterion(output, target)\n",
    "    train_loss = loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    if running_norms is not None:\n",
    "        gradient_norms = optimizer.step(running_norms)\n",
    "        gradient_norms_sq = gradient_norms * gradient_norms\n",
    "        return train_loss, train_acc, gradient_norms_sq\n",
    "    \n",
    "    else:\n",
    "        optimizer.step()\n",
    "        return train_loss, train_acc\n",
    "    \n",
    "\n",
    "def test(model, device, test_loader, criterion, metric):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, target = next(iter(test_loader))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss = criterion(output, target).item()\n",
    "        \n",
    "        correct = metric(target.detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "        test_acc = 1. * correct / len(target)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31adeb5a",
   "metadata": {},
   "source": [
    "# GD with RDP Filter (NeurIPS'21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0aea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdp import PrivacyEngine\n",
    "from fedrpdp.accountants.utils import get_noise_multiplier\n",
    "\n",
    "def generate_rdp_orders():\n",
    "    dense = 1.07\n",
    "    alpha_list = [int(dense ** i + 1) for i in range(int(math.floor(math.log(1000, dense))) + 1)]\n",
    "    alpha_list = np.unique(alpha_list)\n",
    "    return alpha_list\n",
    "\n",
    "norm_sq_budgets = [5] * num_level1 + [20] * num_level2 + [100] * num_level3\n",
    "\n",
    "_model = copy.deepcopy(model_init)\n",
    "_train_loader = copy.deepcopy(train_loader)\n",
    "optimizer = optim.SGD(_model.parameters(), lr=lr, momentum=0)\n",
    "criterion = BaselineLoss()\n",
    "privacy_engine = PrivacyEngine(\n",
    "    module=_model,\n",
    "    batch_size=total_points,\n",
    "    sample_size=total_points,\n",
    "    alphas=generate_rdp_orders(),\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    norm_sq_budget=norm_sq_budgets,\n",
    "    should_clip=True,\n",
    ")\n",
    "privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daa9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1: seconds = 0.6004955768585205\n",
      "Train Loss: 0.6580 \t Acc: 0.6173% | δ: 0.001 ε1 = 0.3768 ε2 = 0.3768 ε3 = 0.3768.\n",
      "Test  Loss: 0.6676 \t Acc: 0.5748\n",
      "\n",
      "Epoch: 2: seconds = 0.008775472640991211\n",
      "Train Loss: 0.6435 \t Acc: 0.6276% | δ: 0.001 ε1 = 0.5358 ε2 = 0.5358 ε3 = 0.5358.\n",
      "Test  Loss: 0.6536 \t Acc: 0.5984\n",
      "\n",
      "Epoch: 3: seconds = 0.008673906326293945\n",
      "Train Loss: 0.6302 \t Acc: 0.6543% | δ: 0.001 ε1 = 0.6589 ε2 = 0.6589 ε3 = 0.6589.\n",
      "Test  Loss: 0.6409 \t Acc: 0.6063\n",
      "\n",
      "Epoch: 4: seconds = 0.008498907089233398\n",
      "Train Loss: 0.6182 \t Acc: 0.6626% | δ: 0.001 ε1 = 0.7636 ε2 = 0.7636 ε3 = 0.7636.\n",
      "Test  Loss: 0.6303 \t Acc: 0.6220\n",
      "\n",
      "Epoch: 5: seconds = 0.008757829666137695\n",
      "Train Loss: 0.6076 \t Acc: 0.6790% | δ: 0.001 ε1 = 0.8563 ε2 = 0.8563 ε3 = 0.8563.\n",
      "Test  Loss: 0.6181 \t Acc: 0.6378\n",
      "\n",
      "Epoch: 6: seconds = 0.008407354354858398\n",
      "Train Loss: 0.5962 \t Acc: 0.6996% | δ: 0.001 ε1 = 0.8563 ε2 = 0.9417 ε3 = 0.9417.\n",
      "Test  Loss: 0.6133 \t Acc: 0.6457\n",
      "\n",
      "Epoch: 7: seconds = 0.008812904357910156\n",
      "Train Loss: 0.5918 \t Acc: 0.7037% | δ: 0.001 ε1 = 0.8563 ε2 = 1.0184 ε3 = 1.0184.\n",
      "Test  Loss: 0.6099 \t Acc: 0.6457\n",
      "\n",
      "Epoch: 8: seconds = 0.008390426635742188\n",
      "Train Loss: 0.5883 \t Acc: 0.7099% | δ: 0.001 ε1 = 0.8563 ε2 = 1.0914 ε3 = 1.0914.\n",
      "Test  Loss: 0.6071 \t Acc: 0.6575\n",
      "\n",
      "Epoch: 9: seconds = 0.008436441421508789\n",
      "Train Loss: 0.5853 \t Acc: 0.7202% | δ: 0.001 ε1 = 0.8563 ε2 = 1.1606 ε3 = 1.1606.\n",
      "Test  Loss: 0.6026 \t Acc: 0.6575\n",
      "\n",
      "Epoch: 10: seconds = 0.008428573608398438\n",
      "Train Loss: 0.5811 \t Acc: 0.7284% | δ: 0.001 ε1 = 0.8563 ε2 = 1.2256 ε3 = 1.2256.\n",
      "Test  Loss: 0.5990 \t Acc: 0.6575\n",
      "\n",
      "Epoch: 11: seconds = 0.008786916732788086\n",
      "Train Loss: 0.5778 \t Acc: 0.7284% | δ: 0.001 ε1 = 0.8563 ε2 = 1.2880 ε3 = 1.2880.\n",
      "Test  Loss: 0.5938 \t Acc: 0.6654\n",
      "\n",
      "Epoch: 12: seconds = 0.008585214614868164\n",
      "Train Loss: 0.5727 \t Acc: 0.7284% | δ: 0.001 ε1 = 0.8563 ε2 = 1.3480 ε3 = 1.3480.\n",
      "Test  Loss: 0.5906 \t Acc: 0.6732\n",
      "\n",
      "Epoch: 13: seconds = 0.00859689712524414\n",
      "Train Loss: 0.5696 \t Acc: 0.7284% | δ: 0.001 ε1 = 0.8563 ε2 = 1.4058 ε3 = 1.4058.\n",
      "Test  Loss: 0.5866 \t Acc: 0.6772\n",
      "\n",
      "Epoch: 14: seconds = 0.008520841598510742\n",
      "Train Loss: 0.5662 \t Acc: 0.7263% | δ: 0.001 ε1 = 0.8563 ε2 = 1.4608 ε3 = 1.4608.\n",
      "Test  Loss: 0.5837 \t Acc: 0.6850\n",
      "\n",
      "Epoch: 15: seconds = 0.008367776870727539\n",
      "Train Loss: 0.5635 \t Acc: 0.7305% | δ: 0.001 ε1 = 0.8563 ε2 = 1.5158 ε3 = 1.5158.\n",
      "Test  Loss: 0.5808 \t Acc: 0.6890\n",
      "\n",
      "Epoch: 16: seconds = 0.008467435836791992\n",
      "Train Loss: 0.5607 \t Acc: 0.7325% | δ: 0.001 ε1 = 0.8563 ε2 = 1.5675 ε3 = 1.5675.\n",
      "Test  Loss: 0.5775 \t Acc: 0.6890\n",
      "\n",
      "Epoch: 17: seconds = 0.008463859558105469\n",
      "Train Loss: 0.5574 \t Acc: 0.7366% | δ: 0.001 ε1 = 0.8563 ε2 = 1.6175 ε3 = 1.6175.\n",
      "Test  Loss: 0.5741 \t Acc: 0.6929\n",
      "\n",
      "Epoch: 18: seconds = 0.008569955825805664\n",
      "Train Loss: 0.5542 \t Acc: 0.7366% | δ: 0.001 ε1 = 0.8563 ε2 = 1.6675 ε3 = 1.6675.\n",
      "Test  Loss: 0.5719 \t Acc: 0.6929\n",
      "\n",
      "Epoch: 19: seconds = 0.008484125137329102\n",
      "Train Loss: 0.5522 \t Acc: 0.7407% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7175 ε3 = 1.7175.\n",
      "Test  Loss: 0.5688 \t Acc: 0.6969\n",
      "\n",
      "Epoch: 20: seconds = 0.008266687393188477\n",
      "Train Loss: 0.5492 \t Acc: 0.7428% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.7635.\n",
      "Test  Loss: 0.5670 \t Acc: 0.6969\n",
      "\n",
      "Epoch: 21: seconds = 0.008746623992919922\n",
      "Train Loss: 0.5473 \t Acc: 0.7428% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.8085.\n",
      "Test  Loss: 0.5650 \t Acc: 0.6969\n",
      "\n",
      "Epoch: 22: seconds = 0.008203744888305664\n",
      "Train Loss: 0.5452 \t Acc: 0.7469% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.8535.\n",
      "Test  Loss: 0.5624 \t Acc: 0.6969\n",
      "\n",
      "Epoch: 23: seconds = 0.00876164436340332\n",
      "Train Loss: 0.5430 \t Acc: 0.7490% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.8985.\n",
      "Test  Loss: 0.5610 \t Acc: 0.7008\n",
      "\n",
      "Epoch: 24: seconds = 0.008243560791015625\n",
      "Train Loss: 0.5416 \t Acc: 0.7469% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.9435.\n",
      "Test  Loss: 0.5586 \t Acc: 0.7008\n",
      "\n",
      "Epoch: 25: seconds = 0.008570671081542969\n",
      "Train Loss: 0.5394 \t Acc: 0.7469% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 1.9868.\n",
      "Test  Loss: 0.5562 \t Acc: 0.7008\n",
      "\n",
      "Epoch: 26: seconds = 0.008618354797363281\n",
      "Train Loss: 0.5371 \t Acc: 0.7490% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.0268.\n",
      "Test  Loss: 0.5554 \t Acc: 0.7008\n",
      "\n",
      "Epoch: 27: seconds = 0.008617639541625977\n",
      "Train Loss: 0.5362 \t Acc: 0.7490% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.0668.\n",
      "Test  Loss: 0.5541 \t Acc: 0.7008\n",
      "\n",
      "Epoch: 28: seconds = 0.008342742919921875\n",
      "Train Loss: 0.5354 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.1068.\n",
      "Test  Loss: 0.5523 \t Acc: 0.7047\n",
      "\n",
      "Epoch: 29: seconds = 0.008439064025878906\n",
      "Train Loss: 0.5341 \t Acc: 0.7531% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.1468.\n",
      "Test  Loss: 0.5515 \t Acc: 0.7126\n",
      "\n",
      "Epoch: 30: seconds = 0.00836801528930664\n",
      "Train Loss: 0.5332 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.1868.\n",
      "Test  Loss: 0.5508 \t Acc: 0.7126\n",
      "\n",
      "Epoch: 31: seconds = 0.008127689361572266\n",
      "Train Loss: 0.5325 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.2268.\n",
      "Test  Loss: 0.5497 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 32: seconds = 0.008399009704589844\n",
      "Train Loss: 0.5311 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.2668.\n",
      "Test  Loss: 0.5476 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 33: seconds = 0.008229970932006836\n",
      "Train Loss: 0.5295 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.3063.\n",
      "Test  Loss: 0.5482 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 34: seconds = 0.008517265319824219\n",
      "Train Loss: 0.5299 \t Acc: 0.7531% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.3413.\n",
      "Test  Loss: 0.5465 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 35: seconds = 0.0084381103515625\n",
      "Train Loss: 0.5284 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.3763.\n",
      "Test  Loss: 0.5453 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 36: seconds = 0.008360147476196289\n",
      "Train Loss: 0.5274 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.4113.\n",
      "Test  Loss: 0.5439 \t Acc: 0.7205\n",
      "\n",
      "Epoch: 37: seconds = 0.008513212203979492\n",
      "Train Loss: 0.5264 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.4463.\n",
      "Test  Loss: 0.5434 \t Acc: 0.7283\n",
      "\n",
      "Epoch: 38: seconds = 0.008510112762451172\n",
      "Train Loss: 0.5260 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.4813.\n",
      "Test  Loss: 0.5415 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 39: seconds = 0.008415699005126953\n",
      "Train Loss: 0.5247 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.5163.\n",
      "Test  Loss: 0.5405 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 40: seconds = 0.008417844772338867\n",
      "Train Loss: 0.5240 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.5513.\n",
      "Test  Loss: 0.5401 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 41: seconds = 0.008578062057495117\n",
      "Train Loss: 0.5235 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.5863.\n",
      "Test  Loss: 0.5392 \t Acc: 0.7323\n",
      "\n",
      "Epoch: 42: seconds = 0.008486270904541016\n",
      "Train Loss: 0.5225 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.6213.\n",
      "Test  Loss: 0.5374 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 43: seconds = 0.008273601531982422\n",
      "Train Loss: 0.5209 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.6563.\n",
      "Test  Loss: 0.5368 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 44: seconds = 0.008148431777954102\n",
      "Train Loss: 0.5203 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.6913.\n",
      "Test  Loss: 0.5358 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 45: seconds = 0.008281946182250977\n",
      "Train Loss: 0.5194 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.7263.\n",
      "Test  Loss: 0.5351 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 46: seconds = 0.008421897888183594\n",
      "Train Loss: 0.5186 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.7613.\n",
      "Test  Loss: 0.5331 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 47: seconds = 0.008550167083740234\n",
      "Train Loss: 0.5169 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.7916.\n",
      "Test  Loss: 0.5320 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 48: seconds = 0.00880122184753418\n",
      "Train Loss: 0.5159 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.8216.\n",
      "Test  Loss: 0.5311 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 49: seconds = 0.008215904235839844\n",
      "Train Loss: 0.5153 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.8516.\n",
      "Test  Loss: 0.5313 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 50: seconds = 0.008751630783081055\n",
      "Train Loss: 0.5152 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.8816.\n",
      "Test  Loss: 0.5323 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 51: seconds = 0.008366584777832031\n",
      "Train Loss: 0.5159 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.9116.\n",
      "Test  Loss: 0.5313 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 52: seconds = 0.008615255355834961\n",
      "Train Loss: 0.5152 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.9416.\n",
      "Test  Loss: 0.5301 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 53: seconds = 0.00834345817565918\n",
      "Train Loss: 0.5142 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 2.9716.\n",
      "Test  Loss: 0.5291 \t Acc: 0.7362\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54: seconds = 0.008536338806152344\n",
      "Train Loss: 0.5134 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.0016.\n",
      "Test  Loss: 0.5284 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 55: seconds = 0.008139371871948242\n",
      "Train Loss: 0.5132 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.0316.\n",
      "Test  Loss: 0.5278 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 56: seconds = 0.008657693862915039\n",
      "Train Loss: 0.5129 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.0616.\n",
      "Test  Loss: 0.5268 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 57: seconds = 0.008078575134277344\n",
      "Train Loss: 0.5123 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.0916.\n",
      "Test  Loss: 0.5250 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 58: seconds = 0.008150100708007812\n",
      "Train Loss: 0.5113 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.1216.\n",
      "Test  Loss: 0.5255 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 59: seconds = 0.008104085922241211\n",
      "Train Loss: 0.5121 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.1516.\n",
      "Test  Loss: 0.5244 \t Acc: 0.7323\n",
      "\n",
      "Epoch: 60: seconds = 0.008177995681762695\n",
      "Train Loss: 0.5110 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.1816.\n",
      "Test  Loss: 0.5242 \t Acc: 0.7323\n",
      "\n",
      "Epoch: 61: seconds = 0.008259773254394531\n",
      "Train Loss: 0.5105 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.2116.\n",
      "Test  Loss: 0.5235 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 62: seconds = 0.00814509391784668\n",
      "Train Loss: 0.5098 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.2416.\n",
      "Test  Loss: 0.5229 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 63: seconds = 0.008172035217285156\n",
      "Train Loss: 0.5093 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.2716.\n",
      "Test  Loss: 0.5217 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 64: seconds = 0.008566856384277344\n",
      "Train Loss: 0.5083 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.3016.\n",
      "Test  Loss: 0.5215 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 65: seconds = 0.008761882781982422\n",
      "Train Loss: 0.5081 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.3316.\n",
      "Test  Loss: 0.5218 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 66: seconds = 0.008396148681640625\n",
      "Train Loss: 0.5083 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.3616.\n",
      "Test  Loss: 0.5211 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 67: seconds = 0.00883340835571289\n",
      "Train Loss: 0.5076 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.3916.\n",
      "Test  Loss: 0.5213 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 68: seconds = 0.008111953735351562\n",
      "Train Loss: 0.5079 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.4216.\n",
      "Test  Loss: 0.5206 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 69: seconds = 0.00813150405883789\n",
      "Train Loss: 0.5074 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.4516.\n",
      "Test  Loss: 0.5198 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 70: seconds = 0.008239030838012695\n",
      "Train Loss: 0.5069 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.4769.\n",
      "Test  Loss: 0.5180 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 71: seconds = 0.008412599563598633\n",
      "Train Loss: 0.5053 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.5019.\n",
      "Test  Loss: 0.5185 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 72: seconds = 0.008222103118896484\n",
      "Train Loss: 0.5055 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.5269.\n",
      "Test  Loss: 0.5185 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 73: seconds = 0.008960962295532227\n",
      "Train Loss: 0.5055 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.5519.\n",
      "Test  Loss: 0.5189 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 74: seconds = 0.008542776107788086\n",
      "Train Loss: 0.5055 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.5769.\n",
      "Test  Loss: 0.5190 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 75: seconds = 0.008444786071777344\n",
      "Train Loss: 0.5055 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.6019.\n",
      "Test  Loss: 0.5175 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 76: seconds = 0.00829768180847168\n",
      "Train Loss: 0.5044 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.6269.\n",
      "Test  Loss: 0.5177 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 77: seconds = 0.008297443389892578\n",
      "Train Loss: 0.5047 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.6519.\n",
      "Test  Loss: 0.5160 \t Acc: 0.7362\n",
      "\n",
      "Epoch: 78: seconds = 0.008365869522094727\n",
      "Train Loss: 0.5033 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.6769.\n",
      "Test  Loss: 0.5154 \t Acc: 0.7402\n",
      "\n",
      "Epoch: 79: seconds = 0.008580923080444336\n",
      "Train Loss: 0.5027 \t Acc: 0.7613% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.7019.\n",
      "Test  Loss: 0.5152 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 80: seconds = 0.008162498474121094\n",
      "Train Loss: 0.5024 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.7269.\n",
      "Test  Loss: 0.5153 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 81: seconds = 0.008129119873046875\n",
      "Train Loss: 0.5026 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.7519.\n",
      "Test  Loss: 0.5146 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 82: seconds = 0.008452892303466797\n",
      "Train Loss: 0.5018 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.7769.\n",
      "Test  Loss: 0.5137 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 83: seconds = 0.00815439224243164\n",
      "Train Loss: 0.5010 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.8019.\n",
      "Test  Loss: 0.5135 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 84: seconds = 0.008196830749511719\n",
      "Train Loss: 0.5012 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.8269.\n",
      "Test  Loss: 0.5138 \t Acc: 0.7441\n",
      "\n",
      "Epoch: 85: seconds = 0.008375883102416992\n",
      "Train Loss: 0.5017 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.8519.\n",
      "Test  Loss: 0.5134 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 86: seconds = 0.008121252059936523\n",
      "Train Loss: 0.5011 \t Acc: 0.7593% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.8769.\n",
      "Test  Loss: 0.5119 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 87: seconds = 0.008187532424926758\n",
      "Train Loss: 0.4998 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.9019.\n",
      "Test  Loss: 0.5120 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 88: seconds = 0.008153676986694336\n",
      "Train Loss: 0.5004 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.9269.\n",
      "Test  Loss: 0.5111 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 89: seconds = 0.008267641067504883\n",
      "Train Loss: 0.4997 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.9519.\n",
      "Test  Loss: 0.5106 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 90: seconds = 0.00814676284790039\n",
      "Train Loss: 0.4990 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 3.9769.\n",
      "Test  Loss: 0.5100 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 91: seconds = 0.008134126663208008\n",
      "Train Loss: 0.4982 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.0019.\n",
      "Test  Loss: 0.5094 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 92: seconds = 0.008294105529785156\n",
      "Train Loss: 0.4981 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.0269.\n",
      "Test  Loss: 0.5090 \t Acc: 0.7480\n",
      "\n",
      "Epoch: 93: seconds = 0.008269309997558594\n",
      "Train Loss: 0.4977 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.0519.\n",
      "Test  Loss: 0.5086 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 94: seconds = 0.008737564086914062\n",
      "Train Loss: 0.4974 \t Acc: 0.7572% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.0769.\n",
      "Test  Loss: 0.5084 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 95: seconds = 0.008140325546264648\n",
      "Train Loss: 0.4974 \t Acc: 0.7551% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.1019.\n",
      "Test  Loss: 0.5069 \t Acc: 0.7520\n",
      "\n",
      "Epoch: 96: seconds = 0.008367300033569336\n",
      "Train Loss: 0.4961 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.1269.\n",
      "Test  Loss: 0.5064 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 97: seconds = 0.008654594421386719\n",
      "Train Loss: 0.4956 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.1519.\n",
      "Test  Loss: 0.5055 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 98: seconds = 0.008373498916625977\n",
      "Train Loss: 0.4946 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.1769.\n",
      "Test  Loss: 0.5058 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 99: seconds = 0.008196115493774414\n",
      "Train Loss: 0.4948 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2019.\n",
      "Test  Loss: 0.5054 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 100: seconds = 0.008006095886230469\n",
      "Train Loss: 0.4945 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5050 \t Acc: 0.7559\n",
      "\n",
      "Epoch: 101: seconds = 0.00839543342590332\n",
      "Train Loss: 0.4941 \t Acc: 0.7634% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5045 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 102: seconds = 0.00819540023803711\n",
      "Train Loss: 0.4936 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5040 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 103: seconds = 0.008178949356079102\n",
      "Train Loss: 0.4932 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5038 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 104: seconds = 0.008432626724243164\n",
      "Train Loss: 0.4930 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5037 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 105: seconds = 0.008207559585571289\n",
      "Train Loss: 0.4926 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5029 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 106: seconds = 0.00857090950012207\n",
      "Train Loss: 0.4922 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5019 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 107: seconds = 0.00832676887512207\n",
      "Train Loss: 0.4917 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5020 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 108: seconds = 0.008109807968139648\n",
      "Train Loss: 0.4918 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5015 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 109: seconds = 0.08444523811340332\n",
      "Train Loss: 0.4913 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5017 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 110: seconds = 0.008585929870605469\n",
      "Train Loss: 0.4914 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5018 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 111: seconds = 0.008423805236816406\n",
      "Train Loss: 0.4914 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5012 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 112: seconds = 0.00844883918762207\n",
      "Train Loss: 0.4908 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5014 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 113: seconds = 0.00823068618774414\n",
      "Train Loss: 0.4908 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5010 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 114: seconds = 0.008767843246459961\n",
      "Train Loss: 0.4900 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5008 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 115: seconds = 0.008516311645507812\n",
      "Train Loss: 0.4897 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5007 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 116: seconds = 0.008466005325317383\n",
      "Train Loss: 0.4897 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5012 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 117: seconds = 0.008597612380981445\n",
      "Train Loss: 0.4897 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5015 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 118: seconds = 0.00890350341796875\n",
      "Train Loss: 0.4901 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5018 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 119: seconds = 0.008781671524047852\n",
      "Train Loss: 0.4903 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5018 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 120: seconds = 0.008536815643310547\n",
      "Train Loss: 0.4905 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5021 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 121: seconds = 0.008438825607299805\n",
      "Train Loss: 0.4906 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5014 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 122: seconds = 0.008434772491455078\n",
      "Train Loss: 0.4902 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5014 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 123: seconds = 0.008925199508666992\n",
      "Train Loss: 0.4902 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5007 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 124: seconds = 0.008437156677246094\n",
      "Train Loss: 0.4899 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5004 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 125: seconds = 0.00827336311340332\n",
      "Train Loss: 0.4897 \t Acc: 0.7654% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.5001 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 126: seconds = 0.008738279342651367\n",
      "Train Loss: 0.4893 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4988 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 127: seconds = 0.008654356002807617\n",
      "Train Loss: 0.4882 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4986 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 128: seconds = 0.008584260940551758\n",
      "Train Loss: 0.4880 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4997 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 129: seconds = 0.008621931076049805\n",
      "Train Loss: 0.4886 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4984 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 130: seconds = 0.008593559265136719\n",
      "Train Loss: 0.4876 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4984 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 131: seconds = 0.008804082870483398\n",
      "Train Loss: 0.4875 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4987 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 132: seconds = 0.008737802505493164\n",
      "Train Loss: 0.4875 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4983 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 133: seconds = 0.008789777755737305\n",
      "Train Loss: 0.4874 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4982 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 134: seconds = 0.008662700653076172\n",
      "Train Loss: 0.4873 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4977 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 135: seconds = 0.008469820022583008\n",
      "Train Loss: 0.4868 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4973 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 136: seconds = 0.008512496948242188\n",
      "Train Loss: 0.4866 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4977 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 137: seconds = 0.008559942245483398\n",
      "Train Loss: 0.4870 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4978 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 138: seconds = 0.008597850799560547\n",
      "Train Loss: 0.4870 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4973 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 139: seconds = 0.008685588836669922\n",
      "Train Loss: 0.4866 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4978 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 140: seconds = 0.008783340454101562\n",
      "Train Loss: 0.4869 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4989 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 141: seconds = 0.008817195892333984\n",
      "Train Loss: 0.4879 \t Acc: 0.7675% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4983 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 142: seconds = 0.00885462760925293\n",
      "Train Loss: 0.4873 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4985 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 143: seconds = 0.008674860000610352\n",
      "Train Loss: 0.4875 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4982 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 144: seconds = 0.009015083312988281\n",
      "Train Loss: 0.4872 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4977 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 145: seconds = 0.008499383926391602\n",
      "Train Loss: 0.4865 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4977 \t Acc: 0.7677\n",
      "\n",
      "Epoch: 146: seconds = 0.008447647094726562\n",
      "Train Loss: 0.4865 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4966 \t Acc: 0.7638\n",
      "\n",
      "Epoch: 147: seconds = 0.008506059646606445\n",
      "Train Loss: 0.4857 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4965 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 148: seconds = 0.008547544479370117\n",
      "Train Loss: 0.4855 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4962 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 149: seconds = 0.008382558822631836\n",
      "Train Loss: 0.4854 \t Acc: 0.7716% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4964 \t Acc: 0.7598\n",
      "\n",
      "Epoch: 150: seconds = 0.00836181640625\n",
      "Train Loss: 0.4856 \t Acc: 0.7695% | δ: 0.001 ε1 = 0.8563 ε2 = 1.7635 ε3 = 4.2269.\n",
      "Test  Loss: 0.4962 \t Acc: 0.7638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "running_grad_sq_norms = [ torch.Tensor([0] * total_points).to(device) ]\n",
    "results_all_reps = [\n",
    "    {\n",
    "        \"test_loss\": 0, \n",
    "        \"test_acc\": 0, \n",
    "        \"seconds\": 0, \n",
    "        \"num_active_points\": total_points,\n",
    "        \"norm_sq_budgets\": set(norm_sq_budgets), \n",
    "        \"e\": json.dumps({0: 0, num_level1:0, num_level1+num_level2:0}), \n",
    "        \"d\": delta, \n",
    "        \"nm\": round(noise_multiplier, 2), \n",
    "        \"norm\": max_grad_norm\n",
    "    }\n",
    "]\n",
    "\n",
    "for epoch in range(1, max_epochs + 51):\n",
    "    # compute activate points\n",
    "    temp = running_grad_sq_norms[-1].cpu().numpy()\n",
    "    num_active_points = np.sum(np.round(temp, 4) < np.array(norm_sq_budgets))\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, grad_sq_norms = train(_model, device, _train_loader, optimizer, criterion, metric, running_grad_sq_norms[-1])\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "    running_grad_sq_norms.append(running_grad_sq_norms[-1] + grad_sq_norms)\n",
    "    \n",
    "    epsilon1 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[0], delta)[0]\n",
    "    epsilon2 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1], delta)[0]\n",
    "    epsilon3 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1 + num_level2], delta)[0]\n",
    "    \n",
    "    temp = running_grad_sq_norms[-1].cpu().numpy()\n",
    "    print(f\"Epoch: {epoch}: seconds = {seconds}\")\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.4f} \\t Acc: {train_acc:.4f}\"\n",
    "        f\"| δ: {delta} ε1 = {epsilon1:.4f} ε2 = {epsilon2:.4f} ε3 = {epsilon3:.4f}.\"\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = test(_model, device, test_loader, criterion, metric)\n",
    "    print(\n",
    "        f\"Test  Loss: {test_loss:.4f} \\t Acc: {test_acc:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    results_all_reps.append(\n",
    "        {\n",
    "            \"test_loss\": round(test_loss,4), \n",
    "            \"test_acc\": round(test_acc,4), \n",
    "            \"seconds\": round(seconds,4), \n",
    "            \"num_active_points\": num_active_points.item(),\n",
    "            \"norm_sq_budgets\": set(running_grad_sq_norms[-1].cpu().numpy()),\n",
    "            \"e\": json.dumps({0:epsilon1, num_level1:epsilon2, num_level1+num_level2:epsilon3}), \n",
    "            \"d\": delta, \n",
    "            \"nm\": round(noise_multiplier,2), \n",
    "            \"norm\": max_grad_norm\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results = pd.DataFrame.from_dict(results_all_reps)\n",
    "    results.to_csv(\"results_filter.csv\", index=False)\n",
    "    \n",
    "    if num_active_points < 10:\n",
    "        break\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0b0fe",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184f4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_csv(\"results_filter.csv\")\n",
    "# np.array(results[\"seconds\"].tolist()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcf0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_style('whitegrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'}) #风格、轮廓线\n",
    "# legend_font = {'style': 'normal', 'size': 8, 'weight': \"normal\"}\n",
    "# label_font = {'family':'sans-serif', 'size': 10.5, 'weight': \"normal\"}\n",
    "# title_font = {'family':'sans-serif', 'size': 10.5, 'weight': \"bold\"}\n",
    "\n",
    "# # privacy_engine.steps = np.floor(privacy_engine.norm_sq_budget[0]/max_grad_norm**2)\n",
    "# # epsilon1 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[0], delta)[0]\n",
    "# # privacy_engine.steps = np.floor(privacy_engine.norm_sq_budget[num_level1]/max_grad_norm**2)\n",
    "# # epsilon2 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1], delta)[0]\n",
    "# # privacy_engine.steps = np.floor(privacy_engine.norm_sq_budget[num_level1 + num_level2]/max_grad_norm**2)\n",
    "# # epsilon3 = privacy_engine.get_epsilon(privacy_engine.norm_sq_budget[num_level1 + num_level2], delta)[0]\n",
    "\n",
    "# active_points = np.array(results[\"num_active_points\"].tolist())\n",
    "# print(\n",
    "#     f\"δ: {delta} ε1 = {epsilon1:.2f} ε2 = {epsilon2:.2f} ε3 = {epsilon3:.2f}.\"\n",
    "# )\n",
    "# print(active_points)\n",
    "# print(np.floor(norm_sq_budgets[0]/(max_grad_norm**2)), np.floor(norm_sq_budgets[num_level1]/(max_grad_norm**2)), np.floor(norm_sq_budgets[num_level1 + num_level2]/(max_grad_norm**2) ))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(3, 3), constrained_layout=True, dpi=500)\n",
    "# sns.lineplot(data=active_points)\n",
    "# ax.set_xlabel(\"Step\", **label_font)\n",
    "# ax.set_ylabel(f\"Number of active points\", **label_font)\n",
    "# ax.set_ylim(0, 500)\n",
    "# ax.set_title(\"ThreeLevels\", **title_font)\n",
    "# # f\"ThreeLevels\\n ε = {epsilon1:.2f}(70%) / {epsilon2:.2f}(20%) / {epsilon3:.2f}(10%), δ = {delta}\"\n",
    "\n",
    "# plt.axvline(np.floor(norm_sq_budgets[0]/(max_grad_norm**2))+1, 0, 1, c='m', linewidth = 1)\n",
    "# plt.axvline(np.floor(norm_sq_budgets[num_level1]/(max_grad_norm**2))+1, 0, 1, c='m', linewidth = 1)\n",
    "# plt.axvline(np.floor(norm_sq_budgets[num_level1 + num_level2]/(max_grad_norm**2))+1, 0, 1, c='m', linewidth = 1)\n",
    "\n",
    "# plt.savefig('./filter_active_points_heart_disease', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771071d9",
   "metadata": {},
   "source": [
    "# GD with SCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21882f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score of the curve fitting. 0.9998839695905924\n",
      "0.8563 0.2948\n",
      "4.2269 1.0\n",
      "{0.29476189686545673, 0.556964846258241, 1.0}\n",
      "Epoch: 1\n",
      "Train Loss: 0.692424 \t Acc: 55.24% | δ: 0.001 ε1 = 0.0599, ε2 = 0.1257, ε3 = 0.2361, \n",
      "Test  Loss: 0.6654 \t Acc: 57.48%\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 0.694599 \t Acc: 56.99% | δ: 0.001 ε1 = 0.0894, ε2 = 0.1868, ε3 = 0.3546, \n",
      "Test  Loss: 0.6557 \t Acc: 58.27%\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 0.643333 \t Acc: 65.58% | δ: 0.001 ε1 = 0.1129, ε2 = 0.2357, ε3 = 0.4490, \n",
      "Test  Loss: 0.6429 \t Acc: 60.63%\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 0.647404 \t Acc: 64.08% | δ: 0.001 ε1 = 0.1333, ε2 = 0.2778, ε3 = 0.5310, \n",
      "Test  Loss: 0.6340 \t Acc: 61.81%\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 0.618542 \t Acc: 67.76% | δ: 0.001 ε1 = 0.1514, ε2 = 0.3153, ε3 = 0.6043, \n",
      "Test  Loss: 0.6175 \t Acc: 63.39%\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 0.619889 \t Acc: 66.34% | δ: 0.001 ε1 = 0.1681, ε2 = 0.3500, ε3 = 0.6719, \n",
      "Test  Loss: 0.6048 \t Acc: 64.57%\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 0.598616 \t Acc: 69.86% | δ: 0.001 ε1 = 0.1837, ε2 = 0.3822, ε3 = 0.7351, \n",
      "Test  Loss: 0.5931 \t Acc: 66.54%\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 0.590385 \t Acc: 72.64% | δ: 0.001 ε1 = 0.1983, ε2 = 0.4125, ε3 = 0.7951, \n",
      "Test  Loss: 0.5791 \t Acc: 68.11%\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 0.575082 \t Acc: 72.34% | δ: 0.001 ε1 = 0.2123, ε2 = 0.4413, ε3 = 0.8507, \n",
      "Test  Loss: 0.5690 \t Acc: 68.90%\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 0.592367 \t Acc: 70.20% | δ: 0.001 ε1 = 0.2254, ε2 = 0.4688, ε3 = 0.9057, \n",
      "Test  Loss: 0.5632 \t Acc: 70.08%\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 0.565041 \t Acc: 76.37% | δ: 0.001 ε1 = 0.2382, ε2 = 0.4962, ε3 = 0.9563, \n",
      "Test  Loss: 0.5566 \t Acc: 70.87%\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 0.529123 \t Acc: 77.42% | δ: 0.001 ε1 = 0.2502, ε2 = 0.5204, ε3 = 1.0063, \n",
      "Test  Loss: 0.5483 \t Acc: 72.05%\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 0.548953 \t Acc: 76.06% | δ: 0.001 ε1 = 0.2619, ε2 = 0.5445, ε3 = 1.0560, \n",
      "Test  Loss: 0.5391 \t Acc: 74.02%\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 0.505005 \t Acc: 77.99% | δ: 0.001 ε1 = 0.2734, ε2 = 0.5686, ε3 = 1.1010, \n",
      "Test  Loss: 0.5316 \t Acc: 74.41%\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 0.523229 \t Acc: 76.39% | δ: 0.001 ε1 = 0.2845, ε2 = 0.5911, ε3 = 1.1460, \n",
      "Test  Loss: 0.5275 \t Acc: 74.80%\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 0.531958 \t Acc: 78.22% | δ: 0.001 ε1 = 0.2951, ε2 = 0.6135, ε3 = 1.1910, \n",
      "Test  Loss: 0.5244 \t Acc: 75.98%\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 0.524752 \t Acc: 75.25% | δ: 0.001 ε1 = 0.3056, ε2 = 0.6354, ε3 = 1.2360, \n",
      "Test  Loss: 0.5209 \t Acc: 75.98%\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 0.532208 \t Acc: 76.17% | δ: 0.001 ε1 = 0.3156, ε2 = 0.6562, ε3 = 1.2762, \n",
      "Test  Loss: 0.5161 \t Acc: 76.77%\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 0.514235 \t Acc: 77.16% | δ: 0.001 ε1 = 0.3257, ε2 = 0.6770, ε3 = 1.3162, \n",
      "Test  Loss: 0.5102 \t Acc: 76.77%\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 0.494009 \t Acc: 77.98% | δ: 0.001 ε1 = 0.3357, ε2 = 0.6978, ε3 = 1.3562, \n",
      "Test  Loss: 0.5047 \t Acc: 76.38%\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 0.473056 \t Acc: 80.00% | δ: 0.001 ε1 = 0.3451, ε2 = 0.7172, ε3 = 1.3962, \n",
      "Test  Loss: 0.4982 \t Acc: 75.98%\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 0.524469 \t Acc: 77.07% | δ: 0.001 ε1 = 0.3542, ε2 = 0.7363, ε3 = 1.4362, \n",
      "Test  Loss: 0.4935 \t Acc: 77.17%\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 0.507164 \t Acc: 76.89% | δ: 0.001 ε1 = 0.3633, ε2 = 0.7555, ε3 = 1.4762, \n",
      "Test  Loss: 0.4898 \t Acc: 76.77%\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 0.459751 \t Acc: 80.28% | δ: 0.001 ε1 = 0.3723, ε2 = 0.7746, ε3 = 1.5128, \n",
      "Test  Loss: 0.4859 \t Acc: 77.56%\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 0.491944 \t Acc: 77.78% | δ: 0.001 ε1 = 0.3811, ε2 = 0.7934, ε3 = 1.5478, \n",
      "Test  Loss: 0.4819 \t Acc: 77.95%\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 0.481700 \t Acc: 78.79% | δ: 0.001 ε1 = 0.3897, ε2 = 0.8109, ε3 = 1.5828, \n",
      "Test  Loss: 0.4797 \t Acc: 78.35%\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 0.489006 \t Acc: 77.93% | δ: 0.001 ε1 = 0.3983, ε2 = 0.8284, ε3 = 1.6178, \n",
      "Test  Loss: 0.4769 \t Acc: 78.35%\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 0.418688 \t Acc: 81.96% | δ: 0.001 ε1 = 0.4068, ε2 = 0.8459, ε3 = 1.6528, \n",
      "Test  Loss: 0.4748 \t Acc: 78.35%\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 0.473280 \t Acc: 80.28% | δ: 0.001 ε1 = 0.4149, ε2 = 0.8634, ε3 = 1.6878, \n",
      "Test  Loss: 0.4722 \t Acc: 78.35%\n",
      "\n",
      "Epoch: 30\n",
      "Train Loss: 0.443320 \t Acc: 80.86% | δ: 0.001 ε1 = 0.4230, ε2 = 0.8809, ε3 = 1.7228, \n",
      "Test  Loss: 0.4702 \t Acc: 79.13%\n",
      "\n",
      "Epoch: 31\n",
      "Train Loss: 0.450926 \t Acc: 80.29% | δ: 0.001 ε1 = 0.4312, ε2 = 0.8985, ε3 = 1.7578, \n",
      "Test  Loss: 0.4691 \t Acc: 79.13%\n",
      "\n",
      "Epoch: 32\n",
      "Train Loss: 0.457700 \t Acc: 78.76% | δ: 0.001 ε1 = 0.4392, ε2 = 0.9144, ε3 = 1.7928, \n",
      "Test  Loss: 0.4674 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 33\n",
      "Train Loss: 0.476653 \t Acc: 77.57% | δ: 0.001 ε1 = 0.4468, ε2 = 0.9303, ε3 = 1.8278, \n",
      "Test  Loss: 0.4657 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 34\n",
      "Train Loss: 0.431408 \t Acc: 80.63% | δ: 0.001 ε1 = 0.4545, ε2 = 0.9462, ε3 = 1.8609, \n",
      "Test  Loss: 0.4643 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 35\n",
      "Train Loss: 0.416283 \t Acc: 81.34% | δ: 0.001 ε1 = 0.4622, ε2 = 0.9620, ε3 = 1.8909, \n",
      "Test  Loss: 0.4636 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 36\n",
      "Train Loss: 0.449497 \t Acc: 80.98% | δ: 0.001 ε1 = 0.4698, ε2 = 0.9779, ε3 = 1.9209, \n",
      "Test  Loss: 0.4620 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 37\n",
      "Train Loss: 0.452747 \t Acc: 81.28% | δ: 0.001 ε1 = 0.4775, ε2 = 0.9938, ε3 = 1.9509, \n",
      "Test  Loss: 0.4607 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 38\n",
      "Train Loss: 0.451044 \t Acc: 81.53% | δ: 0.001 ε1 = 0.4851, ε2 = 1.0097, ε3 = 1.9809, \n",
      "Test  Loss: 0.4599 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 39\n",
      "Train Loss: 0.448663 \t Acc: 81.64% | δ: 0.001 ε1 = 0.4928, ε2 = 1.0255, ε3 = 2.0109, \n",
      "Test  Loss: 0.4575 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 40\n",
      "Train Loss: 0.449866 \t Acc: 80.10% | δ: 0.001 ε1 = 0.5002, ε2 = 1.0412, ε3 = 2.0409, \n",
      "Test  Loss: 0.4558 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 41\n",
      "Train Loss: 0.440972 \t Acc: 80.19% | δ: 0.001 ε1 = 0.5069, ε2 = 1.0554, ε3 = 2.0709, \n",
      "Test  Loss: 0.4545 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 42\n",
      "Train Loss: 0.423239 \t Acc: 82.16% | δ: 0.001 ε1 = 0.5136, ε2 = 1.0697, ε3 = 2.1009, \n",
      "Test  Loss: 0.4536 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 43\n",
      "Train Loss: 0.433542 \t Acc: 81.22% | δ: 0.001 ε1 = 0.5204, ε2 = 1.0839, ε3 = 2.1309, \n",
      "Test  Loss: 0.4528 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 44\n",
      "Train Loss: 0.433935 \t Acc: 79.57% | δ: 0.001 ε1 = 0.5271, ε2 = 1.0982, ε3 = 2.1609, \n",
      "Test  Loss: 0.4519 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 45\n",
      "Train Loss: 0.411427 \t Acc: 81.28% | δ: 0.001 ε1 = 0.5338, ε2 = 1.1125, ε3 = 2.1909, \n",
      "Test  Loss: 0.4512 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 46\n",
      "Train Loss: 0.440552 \t Acc: 79.40% | δ: 0.001 ε1 = 0.5406, ε2 = 1.1267, ε3 = 2.2209, \n",
      "Test  Loss: 0.4504 \t Acc: 79.53%\n",
      "\n",
      "Epoch: 47\n",
      "Train Loss: 0.428117 \t Acc: 80.82% | δ: 0.001 ε1 = 0.5473, ε2 = 1.1410, ε3 = 2.2509, \n",
      "Test  Loss: 0.4502 \t Acc: 79.53%\n",
      "\n",
      "Epoch: 48\n",
      "Train Loss: 0.363451 \t Acc: 84.00% | δ: 0.001 ε1 = 0.5540, ε2 = 1.1552, ε3 = 2.2809, \n",
      "Test  Loss: 0.4494 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 49\n",
      "Train Loss: 0.397367 \t Acc: 83.50% | δ: 0.001 ε1 = 0.5608, ε2 = 1.1695, ε3 = 2.3109, \n",
      "Test  Loss: 0.4487 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 50\n",
      "Train Loss: 0.413883 \t Acc: 82.16% | δ: 0.001 ε1 = 0.5675, ε2 = 1.1837, ε3 = 2.3409, \n",
      "Test  Loss: 0.4489 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 51\n",
      "Train Loss: 0.372778 \t Acc: 84.10% | δ: 0.001 ε1 = 0.5739, ε2 = 1.1980, ε3 = 2.3709, \n",
      "Test  Loss: 0.4485 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 52\n",
      "Train Loss: 0.417065 \t Acc: 82.91% | δ: 0.001 ε1 = 0.5802, ε2 = 1.2122, ε3 = 2.4009, \n",
      "Test  Loss: 0.4477 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 53\n",
      "Train Loss: 0.424463 \t Acc: 80.20% | δ: 0.001 ε1 = 0.5864, ε2 = 1.2261, ε3 = 2.4264, \n",
      "Test  Loss: 0.4469 \t Acc: 79.92%\n",
      "\n",
      "Epoch: 54\n",
      "Train Loss: 0.436587 \t Acc: 80.51% | δ: 0.001 ε1 = 0.5927, ε2 = 1.2387, ε3 = 2.4514, \n",
      "Test  Loss: 0.4469 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 55\n",
      "Train Loss: 0.437789 \t Acc: 78.89% | δ: 0.001 ε1 = 0.5990, ε2 = 1.2513, ε3 = 2.4764, \n",
      "Test  Loss: 0.4461 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 56\n",
      "Train Loss: 0.464339 \t Acc: 80.39% | δ: 0.001 ε1 = 0.6052, ε2 = 1.2640, ε3 = 2.5014, \n",
      "Test  Loss: 0.4455 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 57\n",
      "Train Loss: 0.366749 \t Acc: 85.02% | δ: 0.001 ε1 = 0.6115, ε2 = 1.2766, ε3 = 2.5264, \n",
      "Test  Loss: 0.4445 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 58\n",
      "Train Loss: 0.458112 \t Acc: 79.65% | δ: 0.001 ε1 = 0.6178, ε2 = 1.2893, ε3 = 2.5514, \n",
      "Test  Loss: 0.4442 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 59\n",
      "Train Loss: 0.391199 \t Acc: 81.68% | δ: 0.001 ε1 = 0.6240, ε2 = 1.3019, ε3 = 2.5764, \n",
      "Test  Loss: 0.4437 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 60\n",
      "Train Loss: 0.478911 \t Acc: 76.56% | δ: 0.001 ε1 = 0.6303, ε2 = 1.3145, ε3 = 2.6014, \n",
      "Test  Loss: 0.4438 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 61\n",
      "Train Loss: 0.459410 \t Acc: 78.03% | δ: 0.001 ε1 = 0.6361, ε2 = 1.3272, ε3 = 2.6264, \n",
      "Test  Loss: 0.4437 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 62\n",
      "Train Loss: 0.378378 \t Acc: 84.18% | δ: 0.001 ε1 = 0.6419, ε2 = 1.3398, ε3 = 2.6514, \n",
      "Test  Loss: 0.4437 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 63\n",
      "Train Loss: 0.378758 \t Acc: 82.84% | δ: 0.001 ε1 = 0.6477, ε2 = 1.3524, ε3 = 2.6764, \n",
      "Test  Loss: 0.4429 \t Acc: 80.31%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64\n",
      "Train Loss: 0.471411 \t Acc: 79.26% | δ: 0.001 ε1 = 0.6535, ε2 = 1.3651, ε3 = 2.7014, \n",
      "Test  Loss: 0.4427 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 65\n",
      "Train Loss: 0.377675 \t Acc: 83.08% | δ: 0.001 ε1 = 0.6593, ε2 = 1.3777, ε3 = 2.7264, \n",
      "Test  Loss: 0.4432 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 66\n",
      "Train Loss: 0.403498 \t Acc: 82.03% | δ: 0.001 ε1 = 0.6651, ε2 = 1.3904, ε3 = 2.7514, \n",
      "Test  Loss: 0.4429 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 67\n",
      "Train Loss: 0.378754 \t Acc: 83.10% | δ: 0.001 ε1 = 0.6710, ε2 = 1.4030, ε3 = 2.7764, \n",
      "Test  Loss: 0.4442 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 68\n",
      "Train Loss: 0.436187 \t Acc: 80.10% | δ: 0.001 ε1 = 0.6768, ε2 = 1.4156, ε3 = 2.8014, \n",
      "Test  Loss: 0.4438 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 69\n",
      "Train Loss: 0.481578 \t Acc: 78.40% | δ: 0.001 ε1 = 0.6826, ε2 = 1.4283, ε3 = 2.8264, \n",
      "Test  Loss: 0.4437 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 70\n",
      "Train Loss: 0.471566 \t Acc: 79.79% | δ: 0.001 ε1 = 0.6884, ε2 = 1.4409, ε3 = 2.8514, \n",
      "Test  Loss: 0.4439 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 71\n",
      "Train Loss: 0.420274 \t Acc: 82.59% | δ: 0.001 ε1 = 0.6942, ε2 = 1.4535, ε3 = 2.8764, \n",
      "Test  Loss: 0.4432 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 72\n",
      "Train Loss: 0.470887 \t Acc: 79.59% | δ: 0.001 ε1 = 0.7000, ε2 = 1.4662, ε3 = 2.9014, \n",
      "Test  Loss: 0.4428 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 73\n",
      "Train Loss: 0.485724 \t Acc: 76.77% | δ: 0.001 ε1 = 0.7056, ε2 = 1.4781, ε3 = 2.9264, \n",
      "Test  Loss: 0.4433 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 74\n",
      "Train Loss: 0.427647 \t Acc: 79.90% | δ: 0.001 ε1 = 0.7109, ε2 = 1.4891, ε3 = 2.9514, \n",
      "Test  Loss: 0.4438 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 75\n",
      "Train Loss: 0.462176 \t Acc: 80.29% | δ: 0.001 ε1 = 0.7163, ε2 = 1.5001, ε3 = 2.9764, \n",
      "Test  Loss: 0.4436 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 76\n",
      "Train Loss: 0.492982 \t Acc: 79.02% | δ: 0.001 ε1 = 0.7216, ε2 = 1.5112, ε3 = 3.0014, \n",
      "Test  Loss: 0.4431 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 77\n",
      "Train Loss: 0.437456 \t Acc: 80.00% | δ: 0.001 ε1 = 0.7270, ε2 = 1.5222, ε3 = 3.0264, \n",
      "Test  Loss: 0.4428 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 78\n",
      "Train Loss: 0.420057 \t Acc: 82.32% | δ: 0.001 ε1 = 0.7323, ε2 = 1.5332, ε3 = 3.0514, \n",
      "Test  Loss: 0.4436 \t Acc: 80.71%\n",
      "\n",
      "Epoch: 79\n",
      "Train Loss: 0.443581 \t Acc: 81.50% | δ: 0.001 ε1 = 0.7376, ε2 = 1.5443, ε3 = 3.0764, \n",
      "Test  Loss: 0.4432 \t Acc: 80.31%\n",
      "\n",
      "Epoch: 80\n",
      "Train Loss: 0.436883 \t Acc: 79.25% | δ: 0.001 ε1 = 0.7430, ε2 = 1.5553, ε3 = 3.1014, \n",
      "Test  Loss: 0.4424 \t Acc: 81.10%\n",
      "\n",
      "Epoch: 81\n",
      "Train Loss: 0.473748 \t Acc: 80.10% | δ: 0.001 ε1 = 0.7483, ε2 = 1.5663, ε3 = 3.1264, \n",
      "Test  Loss: 0.4423 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 82\n",
      "Train Loss: 0.450388 \t Acc: 81.35% | δ: 0.001 ε1 = 0.7537, ε2 = 1.5774, ε3 = 3.1514, \n",
      "Test  Loss: 0.4422 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 83\n",
      "Train Loss: 0.432539 \t Acc: 80.98% | δ: 0.001 ε1 = 0.7590, ε2 = 1.5884, ε3 = 3.1764, \n",
      "Test  Loss: 0.4424 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 84\n",
      "Train Loss: 0.458472 \t Acc: 79.49% | δ: 0.001 ε1 = 0.7644, ε2 = 1.5994, ε3 = 3.2014, \n",
      "Test  Loss: 0.4428 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 85\n",
      "Train Loss: 0.351812 \t Acc: 85.92% | δ: 0.001 ε1 = 0.7697, ε2 = 1.6105, ε3 = 3.2264, \n",
      "Test  Loss: 0.4434 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 86\n",
      "Train Loss: 0.359132 \t Acc: 86.19% | δ: 0.001 ε1 = 0.7751, ε2 = 1.6215, ε3 = 3.2514, \n",
      "Test  Loss: 0.4437 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 87\n",
      "Train Loss: 0.417879 \t Acc: 81.73% | δ: 0.001 ε1 = 0.7804, ε2 = 1.6325, ε3 = 3.2764, \n",
      "Test  Loss: 0.4437 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 88\n",
      "Train Loss: 0.420535 \t Acc: 80.84% | δ: 0.001 ε1 = 0.7858, ε2 = 1.6435, ε3 = 3.3014, \n",
      "Test  Loss: 0.4434 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 89\n",
      "Train Loss: 0.392841 \t Acc: 83.33% | δ: 0.001 ε1 = 0.7911, ε2 = 1.6546, ε3 = 3.3264, \n",
      "Test  Loss: 0.4435 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 90\n",
      "Train Loss: 0.438098 \t Acc: 80.28% | δ: 0.001 ε1 = 0.7960, ε2 = 1.6656, ε3 = 3.3514, \n",
      "Test  Loss: 0.4438 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 91\n",
      "Train Loss: 0.430788 \t Acc: 81.50% | δ: 0.001 ε1 = 0.8009, ε2 = 1.6766, ε3 = 3.3728, \n",
      "Test  Loss: 0.4450 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 92\n",
      "Train Loss: 0.408661 \t Acc: 83.25% | δ: 0.001 ε1 = 0.8058, ε2 = 1.6877, ε3 = 3.3928, \n",
      "Test  Loss: 0.4458 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 93\n",
      "Train Loss: 0.445774 \t Acc: 80.45% | δ: 0.001 ε1 = 0.8107, ε2 = 1.6987, ε3 = 3.4128, \n",
      "Test  Loss: 0.4466 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 94\n",
      "Train Loss: 0.433878 \t Acc: 81.12% | δ: 0.001 ε1 = 0.8156, ε2 = 1.7097, ε3 = 3.4328, \n",
      "Test  Loss: 0.4465 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 95\n",
      "Train Loss: 0.423817 \t Acc: 80.51% | δ: 0.001 ε1 = 0.8205, ε2 = 1.7208, ε3 = 3.4528, \n",
      "Test  Loss: 0.4468 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 96\n",
      "Train Loss: 0.423363 \t Acc: 79.45% | δ: 0.001 ε1 = 0.8254, ε2 = 1.7318, ε3 = 3.4728, \n",
      "Test  Loss: 0.4473 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 97\n",
      "Train Loss: 0.431686 \t Acc: 81.31% | δ: 0.001 ε1 = 0.8303, ε2 = 1.7428, ε3 = 3.4928, \n",
      "Test  Loss: 0.4467 \t Acc: 81.89%\n",
      "\n",
      "Epoch: 98\n",
      "Train Loss: 0.453979 \t Acc: 81.00% | δ: 0.001 ε1 = 0.8352, ε2 = 1.7539, ε3 = 3.5128, \n",
      "Test  Loss: 0.4473 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 99\n",
      "Train Loss: 0.435329 \t Acc: 80.60% | δ: 0.001 ε1 = 0.8401, ε2 = 1.7649, ε3 = 3.5328, \n",
      "Test  Loss: 0.4471 \t Acc: 81.50%\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 0.433864 \t Acc: 79.27% | δ: 0.001 ε1 = 0.8450, ε2 = 1.7759, ε3 = 3.5528, \n",
      "Test  Loss: 0.4467 \t Acc: 81.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fedrpdp.accountants.utils import get_noise_multiplier\n",
    "from fedrpdp import PrivacyEngine\n",
    "\n",
    "curve_fn = get_sample_rate_curve(\n",
    "    target_delta = delta,\n",
    "    noise_multiplier = noise_multiplier,\n",
    "    num_updates = max_epochs,\n",
    "    num_rounds = None,\n",
    "    client_rate = None\n",
    ")\n",
    "epsilon_budgets = [epsilon1] * num_level1 + [epsilon2] * num_level2 + [epsilon3] * num_level3\n",
    "\n",
    "_model = copy.deepcopy(model_init)\n",
    "_train_loader = copy.deepcopy(train_loader)\n",
    "optimizer = optim.SGD(_model.parameters(), lr=lr, momentum=0)\n",
    "criterion = BaselineLoss()\n",
    "\n",
    "privacy_engine = PrivacyEngine(accountant=\"pers_rdp\", noise_multiplier=noise_multiplier)\n",
    "privacy_engine.sample_rate_fn = curve_fn\n",
    "per_sample_rate = [float(privacy_engine.sample_rate_fn(x)) for x in epsilon_budgets]\n",
    "print(round(min(epsilon_budgets),4), round(min(per_sample_rate),4))\n",
    "print(round(max(epsilon_budgets),4), round(max(per_sample_rate),4))\n",
    "if max(per_sample_rate) == 0.0:\n",
    "    raise ValueError(\"Hyper parameter errors! The maximum value of per_sample_rates is zero!\")\n",
    "privacy_engine.sample_rate = per_sample_rate # TODO: make it as an internal func of PrivacyEngine\n",
    "print(set(privacy_engine.sample_rate))\n",
    "\n",
    "_model, optimizer, _train_loader = privacy_engine.make_private_with_personalization(\n",
    "    module=_model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=_train_loader,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm\n",
    ")\n",
    "results_all_reps = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = train(_model, device, _train_loader, optimizer, criterion, metric)\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "    \n",
    "    test_loss, test_acc = test(_model, device, test_loader, criterion, metric)\n",
    "    \n",
    "    epsilon_1 = privacy_engine.get_epsilon(0, delta)\n",
    "    epsilon_2 = privacy_engine.get_epsilon(num_level1, delta)\n",
    "    epsilon_3 = privacy_engine.get_epsilon(num_level1+num_level2, delta)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.6f} \\t Acc: {100*train_acc:.2f}% \"\n",
    "        f\"| δ: {delta} \"\n",
    "        f\"ε1 = {epsilon_1:.4f}, \"\n",
    "        f\"ε2 = {epsilon_2:.4f}, \"\n",
    "        f\"ε3 = {epsilon_3:.4f}, \"\n",
    "    )\n",
    "        \n",
    "    print(\"Test  Loss: {:.4f} \\t Acc: {:.2f}%\\n\".format(test_loss, 100*test_acc))\n",
    "    results_all_reps.append(\n",
    "        {\n",
    "            \"test_loss\": round(test_loss,4), \"test_acc\": round(test_acc,4), \n",
    "             \"seconds\": round(seconds,4),\n",
    "             \"e\": set(epsilon_budgets), \"d\": delta, \"nm\": round(noise_multiplier,2), \"norm\": max_grad_norm\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    results = pd.DataFrame.from_dict(results_all_reps)\n",
    "    results.to_csv(\"results_ours.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488435a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
