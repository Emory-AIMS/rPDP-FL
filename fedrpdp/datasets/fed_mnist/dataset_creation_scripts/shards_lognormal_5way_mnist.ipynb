{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "WAY = 5\n",
    "SHOT = 1200\n",
    "NUM_LABELS = 10\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "DATA_ROOT = '/data/privacyGroup/liujunxu/datasets/mnist/'\n",
    "RES_ROOT = '../metadata/'\n",
    "\n",
    "if not os.path.exists(RES_ROOT):\n",
    "    os.makedirs(RES_ROOT)\n",
    "\n",
    "train_data = MNIST(DATA_ROOT, train=True, download=True, \n",
    "                transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "test_data = MNIST(DATA_ROOT, train=False, download=True, \n",
    "                transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "data, target = train_data.data, train_data.targets\n",
    "print(data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# data = np.concatenate([data], axis=0)\n",
    "# target = np.concatenate([target], axis=0)\n",
    "# print(data.shape, target.shape)\n",
    "\n",
    "data_tr, data_ts = [], []\n",
    "target_tr, target_ts = [], []\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    idx = target==i\n",
    "    data_tr.append(list(data[idx]))\n",
    "    target_tr.append(list(target[idx]))\n",
    "\n",
    "# num_samples of each label\n",
    "print([len(v) for v in data_tr])\n",
    "print(type(data_tr[0][0]))\n",
    "\n",
    "# [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]\n",
    "# <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将原数据集合进行分割\n",
    "\n",
    "1. 共`num_users`个clients，取部分作为train clients，剩下的作为test clients；\n",
    "2. 用一个长度为10的指针数组`idx`，记录每个label已经被“assign”的样本数（或者说下次取samples的时候从哪个位置开始取）\n",
    "3. 每个clients首先分到`n-way k-shot`个samples；\n",
    "4. 进一步，每个clients将会分到`n-way`随机数量的samples，这个随机数服从mu=0,sigma=2的对数正态分布；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 5\n"
     ]
    }
   ],
   "source": [
    "# shards 表示要将全部数据分成多少份\n",
    "# 假设每个Client会应分到 N_WAY 份（N个不同labels，共 N*NUM_CLIENTS 份)\n",
    "# 每份包含 60000 // N // NUM_CLIENTS 个样本\n",
    "NUM_SHARDS = NUM_CLIENTS * WAY \n",
    "NUM_SHARDS_PER_LABEL = len(data) // NUM_LABELS // SHOT\n",
    "print(NUM_SHARDS, NUM_SHARDS_PER_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "0 [1 5 6 7 9]\n",
      "1\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "1 [0 3 4 6 8]\n",
      "2\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "2 [0 3 4 5 7]\n",
      "3\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "3 [1 4 5 6 8]\n",
      "4\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "4 [0 2 3 6 7]\n",
      "5\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "5 [1 2 6 8 9]\n",
      "6\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "6 [3 5 7 8 9]\n",
      "7\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "7 [0 1 2 4 7]\n",
      "8\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "8 [1 2 3 4 9]\n",
      "9\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "9 [0 2 5 8 9]\n"
     ]
    }
   ],
   "source": [
    "# assign\n",
    "# label_count = [0] * NUM_LABELS\n",
    "# np.random.seed(100) # seed 很重要\n",
    "\"\"\"\n",
    "WAY = 2 SHOT=1500 NUM_USERS = 20\n",
    "num_shards = 20 * 2 = 40\n",
    "SHARDS_PER_LABEL = 6000 / 1500 = 4\n",
    "39 // 4 = 9\n",
    "\"\"\"\n",
    "while(True):\n",
    "    ###### SPLIT DATA #######\n",
    "    X = [[] for _ in range(NUM_CLIENTS)]\n",
    "    y = [[] for _ in range(NUM_CLIENTS)]\n",
    "\n",
    "    # 长度为10的数组: 指示每个标签已分配出去的样本数\n",
    "    idx = np.zeros(NUM_LABELS, dtype=np.int64)\n",
    "    shards_index = list(range(NUM_SHARDS))\n",
    "    user_labels_count = {i: [] for i in range(NUM_CLIENTS)}\n",
    "    FINDED = True\n",
    "    for user in range(NUM_CLIENTS):\n",
    "        if user == NUM_CLIENTS-1:\n",
    "            rand_set = set(shards_index)\n",
    "            labels = [idx // NUM_SHARDS_PER_LABEL for idx in rand_set]\n",
    "            if len(set(labels)) < WAY:\n",
    "                print('Failed!')\n",
    "                FINDED = False\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            trials = 0\n",
    "            while(True):\n",
    "                rand_set = set(np.random.choice(shards_index, WAY, replace=False))\n",
    "                if len(rand_set) > WAY: \n",
    "                    continue\n",
    "\n",
    "                labels = [idx // NUM_SHARDS_PER_LABEL for idx in rand_set] # \n",
    "                if len(set(labels)) == WAY:\n",
    "                    break\n",
    "                trials += 1\n",
    "                if trials > 100:\n",
    "                    print('trials > 100, NOT FINDED.')\n",
    "                    FINDED = False\n",
    "                    break\n",
    "        \n",
    "        if FINDED == False:\n",
    "            break\n",
    "\n",
    "        shards_index = list(set(shards_index) - rand_set) # update shards_index\n",
    "        # print(labels)\n",
    "        for idx_lbl, lbl in enumerate(labels): # assign samples for the current user\n",
    "    #         print(lbl, idx[lbl], idx[lbl]+SHOT)\n",
    "            if len(X[user]) == 0:\n",
    "                X[user] = data_tr[lbl][idx[lbl]:idx[lbl]+SHOT]\n",
    "                y[user] = [lbl] * SHOT\n",
    "                idx[lbl] += SHOT # 记录当前标签已分配的样本数\n",
    "                print(user)\n",
    "                print(type(X[user][0]))\n",
    "            else:\n",
    "                X[user].extend(data_tr[lbl][idx[lbl]:idx[lbl]+SHOT])\n",
    "                print(type(X[user][-1]))\n",
    "                y[user].extend([lbl] * SHOT)\n",
    "                idx[lbl] += SHOT # 记录当前标签已分配的样本数\n",
    "            \n",
    "        print(user, np.unique(y[user]))\n",
    "    \n",
    "    if FINDED:\n",
    "        break\n",
    "    #     print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                        | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/home/wamdm/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/numpy/lib/npyio.py:528: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/wamdm/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      " 10%|██████▍                                                         | 1/10 [00:49<07:28, 49.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 20%|████████████▊                                                   | 2/10 [01:39<06:39, 50.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 30%|███████████████████▏                                            | 3/10 [02:30<05:52, 50.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 30%|███████████████████▏                                            | 3/10 [03:05<07:12, 61.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68395/2694420723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{uname}.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     # take 80% as train samples，the rest as test samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 530\u001b[0;31m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/liujunxu_tf1/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Create data structure\n",
    "federated_data = {'users': [], 'user_data':{}, 'num_samples':[], 'classes':{}}\n",
    "save_dir = f\"./niid_{WAY}way_{SHOT}shot\"\n",
    "if not (os.path.exists(save_dir)):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "for user in trange(NUM_CLIENTS, ncols=100):\n",
    "    uname = 'client{:d}'.format(user) \n",
    "    combined = list(zip(X[user], y[user])) \n",
    "    random.shuffle(combined)\n",
    "    print(uname, combined)\n",
    "    np.save(os.path.join(save_dir, f\"{uname}.npy\"), combined)\n",
    "    \n",
    "#     # take 80% as train samples，the rest as test samples\n",
    "#     train_len = int(0.8*len(combined))\n",
    "#     test_len = len(combined) - train_len\n",
    "#     print(uname, len(combined), train_len, test_len)\n",
    "    \n",
    "#     classes = {idx_lbl:int(lbl) for idx_lbl, lbl, _ in user_labels_count[i]}\n",
    "    \n",
    "#     train_data['users'].append(uname) \n",
    "#     train_data['user_data'][uname] = combined[:train_len]\n",
    "#     train_data['num_samples'].append(train_len)\n",
    "#     train_data['classes'][uname] = classes\n",
    "    \n",
    "#     test_data['users'].append(uname)\n",
    "#     test_data['user_data'][uname] = combined[train_len:]\n",
    "#     test_data['num_samples'].append(test_len)\n",
    "#     test_data['classes'][uname] = classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = RES_ROOT + '/all_data_niid_train_{}way_{}shot_82_6000.npy'.format(WAY, SHOT)\n",
    "test_path = RES_ROOT + '/all_data_niid_test_{}way_{}shot_82_6000.npy'.format(WAY, SHOT)\n",
    "np.save(train_path, train_data)\n",
    "np.save(test_path, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RES_ROOT = '/data/privacyGroup/liujunxu/datasets/mnist/type3'\n",
    "train_path = RES_ROOT + '/all_data_niid_train_{}way_{}shot_82_6000.npy'.format(WAY, SHOT)\n",
    "test_path = RES_ROOT + '/all_data_niid_test_{}way_{}shot_82_6000.npy'.format(WAY, SHOT)\n",
    "train_data = np.load(train_path, allow_pickle=True).item()\n",
    "test_data = np.load(test_path, allow_pickle=True).item()\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (32,32,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9585/1289434410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimageid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (32,32,3)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib as plt\n",
    "cid = test_data['users'][2]\n",
    "imageid = 4\n",
    "test_samples = test_data['user_data'][cid]\n",
    "# # print(test_samples[1][0].shape)\n",
    "# plt.figure(1)\n",
    "# plt.imshow(test_samples[imageid][0]) # 使用matplotlib显示彩色图像需要数据的维度为 [W, H, C]，就是224 * 224 * 3\n",
    "# plt.show()\n",
    "# print(test_samples[imageid][1])\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.subplot(111)\n",
    "plt.title('original image')\n",
    "plt.imshow(np.array(test_samples[imageid][0]).reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import MNIST\n",
    "# from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# from tqdm import trange\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# WAY = 5\n",
    "# SHOT = 120\n",
    "# NUM_LABELS = 10\n",
    "# NUM_USERS = 100\n",
    "# RES_ROOT = '/data/privacyGroup/liujunxu/datasets/mnist/type3'\n",
    "# train_path = RES_ROOT + '/all_data_niid_train_55_6000.npy'.format(WAY, SHOT)\n",
    "# test_path = RES_ROOT + '/all_data_niid_test_55_6000.npy'.format(WAY, SHOT)\n",
    "# train_data = np.load(train_path, allow_pickle=True).item()\n",
    "# test_data = np.load(test_path, allow_pickle=True).item()\n",
    "# type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # import matplotlib as plt\n",
    "# cid = test_data['users'][4]\n",
    "# imageid = 4\n",
    "# test_samples = test_data['user_data'][cid]\n",
    "# # # print(test_samples[1][0].shape)\n",
    "# # plt.figure(1)\n",
    "# # plt.imshow(test_samples[imageid][0]) # 使用matplotlib显示彩色图像需要数据的维度为 [W, H, C]，就是224 * 224 * 3\n",
    "# # plt.show()\n",
    "# # print(test_samples[imageid][1])\n",
    "\n",
    "# plt.figure(figsize=(1,1))\n",
    "# plt.subplot(111)\n",
    "# plt.title('original image')\n",
    "# plt.imshow(np.array(test_samples[imageid][0]).reshape(28,28,1))\n",
    "# print(test_samples[imageid][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cd2817a37aac10ac04dd4bd211d68db65c45a714a600fc3dbad943ddf1ad11a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
